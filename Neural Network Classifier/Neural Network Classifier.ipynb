{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74da2e09-dd45-41f9-bb04-55a1a02d702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, ConfusionMatrixDisplay\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification metrics, generates a confusion matrix heatmap,\n",
    "    and saves the metrics to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Neural Network Model Setup ---\n",
    "        # Define a sequential neural network model\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with 64 neurons and ReLU activation\n",
    "        model.add(Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.3))\n",
    "        \n",
    "        # Second hidden layer with 32 neurons and ReLU activation\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        \n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        # Sigmoid function squashes the output to a probability between 0 and 1\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        # Binary cross-entropy is the standard loss function for binary classification\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=50,  # Number of training epochs\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled)\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "        # --- 2. Save Metrics to Excel ---\n",
    "        # Create a dictionary to hold the metrics\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC Score'],\n",
    "            'Value': [accuracy, roc_auc]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_classification_performance.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 3. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9f4ca6b-2142-4893-a88f-6444bc5195e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\River-Flood-Prediction\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,009</span> (11.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,009\u001b[0m (11.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,009</span> (11.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,009\u001b[0m (11.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5113 - loss: 0.7049 - val_accuracy: 0.5063 - val_loss: 0.6967\n",
      "Epoch 2/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5206 - loss: 0.6953 - val_accuracy: 0.5075 - val_loss: 0.6956\n",
      "Epoch 3/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5377 - loss: 0.6917 - val_accuracy: 0.5088 - val_loss: 0.6959\n",
      "Epoch 4/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5337 - loss: 0.6903 - val_accuracy: 0.5231 - val_loss: 0.6944\n",
      "Epoch 5/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5372 - loss: 0.6898 - val_accuracy: 0.5056 - val_loss: 0.6951\n",
      "Epoch 6/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5452 - loss: 0.6866 - val_accuracy: 0.5125 - val_loss: 0.6951\n",
      "Epoch 7/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5442 - loss: 0.6873 - val_accuracy: 0.5094 - val_loss: 0.6962\n",
      "Epoch 8/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5428 - loss: 0.6866 - val_accuracy: 0.5144 - val_loss: 0.6956\n",
      "Epoch 9/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5461 - loss: 0.6863 - val_accuracy: 0.5069 - val_loss: 0.6929\n",
      "Epoch 10/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5462 - loss: 0.6838 - val_accuracy: 0.5144 - val_loss: 0.6946\n",
      "Epoch 11/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5577 - loss: 0.6821 - val_accuracy: 0.5100 - val_loss: 0.6942\n",
      "Epoch 12/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5512 - loss: 0.6835 - val_accuracy: 0.5188 - val_loss: 0.6946\n",
      "Epoch 13/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5616 - loss: 0.6821 - val_accuracy: 0.5144 - val_loss: 0.6952\n",
      "Epoch 14/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5663 - loss: 0.6805 - val_accuracy: 0.5156 - val_loss: 0.6969\n",
      "Epoch 15/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5548 - loss: 0.6801 - val_accuracy: 0.5213 - val_loss: 0.6975\n",
      "Epoch 16/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5542 - loss: 0.6811 - val_accuracy: 0.5275 - val_loss: 0.6942\n",
      "Epoch 17/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5619 - loss: 0.6791 - val_accuracy: 0.5106 - val_loss: 0.6976\n",
      "Epoch 18/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5602 - loss: 0.6798 - val_accuracy: 0.5094 - val_loss: 0.6979\n",
      "Epoch 19/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5713 - loss: 0.6782 - val_accuracy: 0.5081 - val_loss: 0.7006\n",
      "Epoch 20/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5820 - loss: 0.6755 - val_accuracy: 0.5188 - val_loss: 0.6988\n",
      "Epoch 21/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5748 - loss: 0.6746 - val_accuracy: 0.5200 - val_loss: 0.6994\n",
      "Epoch 22/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5755 - loss: 0.6767 - val_accuracy: 0.5088 - val_loss: 0.7007\n",
      "Epoch 23/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5709 - loss: 0.6749 - val_accuracy: 0.5138 - val_loss: 0.6997\n",
      "Epoch 24/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5845 - loss: 0.6713 - val_accuracy: 0.5113 - val_loss: 0.7006\n",
      "Epoch 25/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5850 - loss: 0.6716 - val_accuracy: 0.5000 - val_loss: 0.7007\n",
      "Epoch 26/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5734 - loss: 0.6734 - val_accuracy: 0.5244 - val_loss: 0.6995\n",
      "Epoch 27/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5886 - loss: 0.6701 - val_accuracy: 0.5181 - val_loss: 0.7008\n",
      "Epoch 28/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5800 - loss: 0.6700 - val_accuracy: 0.5113 - val_loss: 0.7004\n",
      "Epoch 29/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5834 - loss: 0.6690 - val_accuracy: 0.5169 - val_loss: 0.7052\n",
      "Epoch 30/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5802 - loss: 0.6687 - val_accuracy: 0.5144 - val_loss: 0.7037\n",
      "Epoch 31/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5856 - loss: 0.6685 - val_accuracy: 0.5163 - val_loss: 0.7040\n",
      "Epoch 32/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5933 - loss: 0.6648 - val_accuracy: 0.5256 - val_loss: 0.7043\n",
      "Epoch 33/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5891 - loss: 0.6686 - val_accuracy: 0.5181 - val_loss: 0.7057\n",
      "Epoch 34/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5905 - loss: 0.6651 - val_accuracy: 0.5244 - val_loss: 0.7045\n",
      "Epoch 35/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5970 - loss: 0.6656 - val_accuracy: 0.5225 - val_loss: 0.7025\n",
      "Epoch 36/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5908 - loss: 0.6656 - val_accuracy: 0.5206 - val_loss: 0.7044\n",
      "Epoch 37/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5966 - loss: 0.6606 - val_accuracy: 0.5263 - val_loss: 0.7072\n",
      "Epoch 38/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5981 - loss: 0.6619 - val_accuracy: 0.5125 - val_loss: 0.7085\n",
      "Epoch 39/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5936 - loss: 0.6628 - val_accuracy: 0.5188 - val_loss: 0.7087\n",
      "Epoch 40/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5967 - loss: 0.6619 - val_accuracy: 0.5131 - val_loss: 0.7079\n",
      "Epoch 41/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5989 - loss: 0.6612 - val_accuracy: 0.5038 - val_loss: 0.7105\n",
      "Epoch 42/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6036 - loss: 0.6597 - val_accuracy: 0.5031 - val_loss: 0.7104\n",
      "Epoch 43/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6003 - loss: 0.6606 - val_accuracy: 0.5169 - val_loss: 0.7094\n",
      "Epoch 44/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6033 - loss: 0.6599 - val_accuracy: 0.5194 - val_loss: 0.7101\n",
      "Epoch 45/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6017 - loss: 0.6605 - val_accuracy: 0.5206 - val_loss: 0.7082\n",
      "Epoch 46/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6012 - loss: 0.6604 - val_accuracy: 0.5144 - val_loss: 0.7118\n",
      "Epoch 47/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5992 - loss: 0.6566 - val_accuracy: 0.5081 - val_loss: 0.7131\n",
      "Epoch 48/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6059 - loss: 0.6598 - val_accuracy: 0.5075 - val_loss: 0.7107\n",
      "Epoch 49/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6123 - loss: 0.6555 - val_accuracy: 0.5056 - val_loss: 0.7130\n",
      "Epoch 50/50\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6042 - loss: 0.6570 - val_accuracy: 0.5050 - val_loss: 0.7138\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.4920\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.36      0.41       989\n",
      "         1.0       0.50      0.62      0.55      1011\n",
      "\n",
      "    accuracy                           0.49      2000\n",
      "   macro avg       0.49      0.49      0.48      2000\n",
      "weighted avg       0.49      0.49      0.48      2000\n",
      "\n",
      "ROC AUC Score: 0.4911\n",
      "\n",
      "Model performance metrics saved to 'nn_classification_performance.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3b3f7a-b8fb-436d-b5a4-324deb0cfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Neural Network Model Setup ---\n",
    "        # Define a more complex sequential neural network model\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with 128 neurons and ReLU activation\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer with 64 neurons and ReLU activation\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        \n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with more epochs\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=100,  # Increased number of training epochs\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        # Add a small epsilon to avoid division by zero\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        # Mean Squared Log Error (MSLE) - check for negative values\n",
    "        # Add a small value to predictions to avoid log(0)\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        # Create a dictionary to hold the metrics\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8dc1106-a06c-4892-812c-bdd6ed680562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\River-Flood-Prediction\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,113</span> (39.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,113\u001b[0m (39.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,113</span> (39.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,113\u001b[0m (39.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4942 - loss: 0.7033 - val_accuracy: 0.5156 - val_loss: 0.6941\n",
      "Epoch 2/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5222 - loss: 0.6951 - val_accuracy: 0.5175 - val_loss: 0.6926\n",
      "Epoch 3/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5331 - loss: 0.6914 - val_accuracy: 0.5206 - val_loss: 0.6926\n",
      "Epoch 4/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5377 - loss: 0.6894 - val_accuracy: 0.5231 - val_loss: 0.6915\n",
      "Epoch 5/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5380 - loss: 0.6886 - val_accuracy: 0.4950 - val_loss: 0.6965\n",
      "Epoch 6/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5403 - loss: 0.6865 - val_accuracy: 0.5069 - val_loss: 0.6938\n",
      "Epoch 7/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5545 - loss: 0.6853 - val_accuracy: 0.5244 - val_loss: 0.6921\n",
      "Epoch 8/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5558 - loss: 0.6834 - val_accuracy: 0.5150 - val_loss: 0.6940\n",
      "Epoch 9/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5686 - loss: 0.6825 - val_accuracy: 0.5119 - val_loss: 0.6952\n",
      "Epoch 10/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5669 - loss: 0.6812 - val_accuracy: 0.5163 - val_loss: 0.6972\n",
      "Epoch 11/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5691 - loss: 0.6788 - val_accuracy: 0.5163 - val_loss: 0.7023\n",
      "Epoch 12/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5705 - loss: 0.6778 - val_accuracy: 0.5094 - val_loss: 0.6992\n",
      "Epoch 13/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5728 - loss: 0.6787 - val_accuracy: 0.5100 - val_loss: 0.6941\n",
      "Epoch 14/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5789 - loss: 0.6753 - val_accuracy: 0.5206 - val_loss: 0.6971\n",
      "Epoch 15/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5758 - loss: 0.6738 - val_accuracy: 0.5194 - val_loss: 0.6963\n",
      "Epoch 16/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5748 - loss: 0.6752 - val_accuracy: 0.5156 - val_loss: 0.6951\n",
      "Epoch 17/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5847 - loss: 0.6713 - val_accuracy: 0.5175 - val_loss: 0.6994\n",
      "Epoch 18/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5844 - loss: 0.6717 - val_accuracy: 0.5113 - val_loss: 0.7022\n",
      "Epoch 19/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5909 - loss: 0.6697 - val_accuracy: 0.5213 - val_loss: 0.6997\n",
      "Epoch 20/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5842 - loss: 0.6690 - val_accuracy: 0.5163 - val_loss: 0.7036\n",
      "Epoch 21/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 0.6653 - val_accuracy: 0.5225 - val_loss: 0.7011\n",
      "Epoch 22/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6025 - loss: 0.6657 - val_accuracy: 0.5431 - val_loss: 0.6996\n",
      "Epoch 23/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5927 - loss: 0.6653 - val_accuracy: 0.5131 - val_loss: 0.7058\n",
      "Epoch 24/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5914 - loss: 0.6658 - val_accuracy: 0.5188 - val_loss: 0.7043\n",
      "Epoch 25/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6017 - loss: 0.6607 - val_accuracy: 0.5169 - val_loss: 0.7061\n",
      "Epoch 26/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6028 - loss: 0.6609 - val_accuracy: 0.5256 - val_loss: 0.7073\n",
      "Epoch 27/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5994 - loss: 0.6595 - val_accuracy: 0.5069 - val_loss: 0.7069\n",
      "Epoch 28/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6037 - loss: 0.6590 - val_accuracy: 0.5088 - val_loss: 0.7121\n",
      "Epoch 29/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 0.6568 - val_accuracy: 0.5100 - val_loss: 0.7105\n",
      "Epoch 30/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6052 - loss: 0.6602 - val_accuracy: 0.5119 - val_loss: 0.7138\n",
      "Epoch 31/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6130 - loss: 0.6550 - val_accuracy: 0.5094 - val_loss: 0.7164\n",
      "Epoch 32/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6072 - loss: 0.6573 - val_accuracy: 0.5100 - val_loss: 0.7157\n",
      "Epoch 33/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6180 - loss: 0.6507 - val_accuracy: 0.5113 - val_loss: 0.7149\n",
      "Epoch 34/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6155 - loss: 0.6527 - val_accuracy: 0.5119 - val_loss: 0.7175\n",
      "Epoch 35/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6175 - loss: 0.6503 - val_accuracy: 0.5100 - val_loss: 0.7183\n",
      "Epoch 36/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6230 - loss: 0.6479 - val_accuracy: 0.5150 - val_loss: 0.7192\n",
      "Epoch 37/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6203 - loss: 0.6493 - val_accuracy: 0.5138 - val_loss: 0.7168\n",
      "Epoch 38/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6167 - loss: 0.6506 - val_accuracy: 0.5119 - val_loss: 0.7190\n",
      "Epoch 39/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6159 - loss: 0.6498 - val_accuracy: 0.5106 - val_loss: 0.7182\n",
      "Epoch 40/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6234 - loss: 0.6502 - val_accuracy: 0.4988 - val_loss: 0.7184\n",
      "Epoch 41/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6217 - loss: 0.6462 - val_accuracy: 0.5150 - val_loss: 0.7203\n",
      "Epoch 42/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6284 - loss: 0.6421 - val_accuracy: 0.5100 - val_loss: 0.7215\n",
      "Epoch 43/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6334 - loss: 0.6403 - val_accuracy: 0.5150 - val_loss: 0.7245\n",
      "Epoch 44/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6320 - loss: 0.6416 - val_accuracy: 0.5156 - val_loss: 0.7272\n",
      "Epoch 45/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6323 - loss: 0.6405 - val_accuracy: 0.5025 - val_loss: 0.7296\n",
      "Epoch 46/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6272 - loss: 0.6387 - val_accuracy: 0.4994 - val_loss: 0.7273\n",
      "Epoch 47/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6388 - loss: 0.6399 - val_accuracy: 0.5094 - val_loss: 0.7270\n",
      "Epoch 48/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6378 - loss: 0.6362 - val_accuracy: 0.5050 - val_loss: 0.7287\n",
      "Epoch 49/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6283 - loss: 0.6372 - val_accuracy: 0.5119 - val_loss: 0.7278\n",
      "Epoch 50/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6364 - loss: 0.6351 - val_accuracy: 0.5013 - val_loss: 0.7291\n",
      "Epoch 51/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6353 - loss: 0.6357 - val_accuracy: 0.4994 - val_loss: 0.7299\n",
      "Epoch 52/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6317 - loss: 0.6341 - val_accuracy: 0.5063 - val_loss: 0.7292\n",
      "Epoch 53/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6270 - loss: 0.6386 - val_accuracy: 0.5069 - val_loss: 0.7310\n",
      "Epoch 54/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6423 - loss: 0.6294 - val_accuracy: 0.5094 - val_loss: 0.7278\n",
      "Epoch 55/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6406 - loss: 0.6300 - val_accuracy: 0.4981 - val_loss: 0.7320\n",
      "Epoch 56/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6409 - loss: 0.6306 - val_accuracy: 0.5025 - val_loss: 0.7344\n",
      "Epoch 57/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6348 - loss: 0.6301 - val_accuracy: 0.5125 - val_loss: 0.7328\n",
      "Epoch 58/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6508 - loss: 0.6258 - val_accuracy: 0.5088 - val_loss: 0.7317\n",
      "Epoch 59/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 0.6310 - val_accuracy: 0.5094 - val_loss: 0.7325\n",
      "Epoch 60/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6498 - loss: 0.6263 - val_accuracy: 0.5169 - val_loss: 0.7311\n",
      "Epoch 61/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6478 - loss: 0.6236 - val_accuracy: 0.5044 - val_loss: 0.7355\n",
      "Epoch 62/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6452 - loss: 0.6215 - val_accuracy: 0.5138 - val_loss: 0.7379\n",
      "Epoch 63/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6530 - loss: 0.6214 - val_accuracy: 0.5069 - val_loss: 0.7484\n",
      "Epoch 64/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6475 - loss: 0.6217 - val_accuracy: 0.5113 - val_loss: 0.7350\n",
      "Epoch 65/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6519 - loss: 0.6236 - val_accuracy: 0.5163 - val_loss: 0.7429\n",
      "Epoch 66/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6442 - loss: 0.6243 - val_accuracy: 0.5081 - val_loss: 0.7372\n",
      "Epoch 67/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6495 - loss: 0.6203 - val_accuracy: 0.5088 - val_loss: 0.7385\n",
      "Epoch 68/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6522 - loss: 0.6171 - val_accuracy: 0.5113 - val_loss: 0.7451\n",
      "Epoch 69/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6448 - loss: 0.6213 - val_accuracy: 0.5013 - val_loss: 0.7427\n",
      "Epoch 70/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6572 - loss: 0.6173 - val_accuracy: 0.5106 - val_loss: 0.7446\n",
      "Epoch 71/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6519 - loss: 0.6194 - val_accuracy: 0.5069 - val_loss: 0.7397\n",
      "Epoch 72/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6547 - loss: 0.6158 - val_accuracy: 0.5119 - val_loss: 0.7412\n",
      "Epoch 73/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6547 - loss: 0.6149 - val_accuracy: 0.5044 - val_loss: 0.7467\n",
      "Epoch 74/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6573 - loss: 0.6122 - val_accuracy: 0.4938 - val_loss: 0.7463\n",
      "Epoch 75/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6533 - loss: 0.6126 - val_accuracy: 0.5113 - val_loss: 0.7435\n",
      "Epoch 76/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 0.6113 - val_accuracy: 0.5088 - val_loss: 0.7474\n",
      "Epoch 77/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6630 - loss: 0.6071 - val_accuracy: 0.5081 - val_loss: 0.7463\n",
      "Epoch 78/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6658 - loss: 0.6124 - val_accuracy: 0.5025 - val_loss: 0.7456\n",
      "Epoch 79/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6511 - loss: 0.6172 - val_accuracy: 0.5094 - val_loss: 0.7417\n",
      "Epoch 80/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6678 - loss: 0.6081 - val_accuracy: 0.5131 - val_loss: 0.7484\n",
      "Epoch 81/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6598 - loss: 0.6090 - val_accuracy: 0.5138 - val_loss: 0.7474\n",
      "Epoch 82/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6612 - loss: 0.6103 - val_accuracy: 0.5113 - val_loss: 0.7440\n",
      "Epoch 83/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6553 - loss: 0.6142 - val_accuracy: 0.5200 - val_loss: 0.7442\n",
      "Epoch 84/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6666 - loss: 0.6083 - val_accuracy: 0.5231 - val_loss: 0.7444\n",
      "Epoch 85/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6647 - loss: 0.6050 - val_accuracy: 0.5038 - val_loss: 0.7468\n",
      "Epoch 86/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6706 - loss: 0.6055 - val_accuracy: 0.5150 - val_loss: 0.7492\n",
      "Epoch 87/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6723 - loss: 0.6052 - val_accuracy: 0.5013 - val_loss: 0.7498\n",
      "Epoch 88/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6777 - loss: 0.5966 - val_accuracy: 0.5088 - val_loss: 0.7574\n",
      "Epoch 89/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6639 - loss: 0.6055 - val_accuracy: 0.5119 - val_loss: 0.7478\n",
      "Epoch 90/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6648 - loss: 0.6057 - val_accuracy: 0.5038 - val_loss: 0.7464\n",
      "Epoch 91/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6702 - loss: 0.6009 - val_accuracy: 0.5131 - val_loss: 0.7474\n",
      "Epoch 92/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6769 - loss: 0.5970 - val_accuracy: 0.5200 - val_loss: 0.7450\n",
      "Epoch 93/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6761 - loss: 0.6004 - val_accuracy: 0.5069 - val_loss: 0.7525\n",
      "Epoch 94/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.6000 - val_accuracy: 0.5125 - val_loss: 0.7527\n",
      "Epoch 95/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6731 - loss: 0.6023 - val_accuracy: 0.5075 - val_loss: 0.7558\n",
      "Epoch 96/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6862 - loss: 0.5925 - val_accuracy: 0.5031 - val_loss: 0.7624\n",
      "Epoch 97/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6848 - loss: 0.5898 - val_accuracy: 0.5106 - val_loss: 0.7611\n",
      "Epoch 98/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6780 - loss: 0.5921 - val_accuracy: 0.5119 - val_loss: 0.7566\n",
      "Epoch 99/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6800 - loss: 0.5949 - val_accuracy: 0.5106 - val_loss: 0.7553\n",
      "Epoch 100/100\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6778 - loss: 0.5961 - val_accuracy: 0.5031 - val_loss: 0.7578\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.5060\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.44      0.47       989\n",
      "         1.0       0.51      0.57      0.54      1011\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.51      0.51      0.50      2000\n",
      "weighted avg       0.51      0.51      0.50      2000\n",
      "\n",
      "ROC AUC Score: 0.5072\n",
      "\n",
      "--- Regression Metrics on Predicted Probabilities ---\n",
      "R-squared (R2): -0.1218\n",
      "Mean Absolute Error (MAE): 0.4976\n",
      "Mean Squared Error (MSE): 0.2804\n",
      "Root Mean Squared Error (RMSE): 0.5295\n",
      "Mean Absolute Percentage Error (MAPE): 2571480747.10%\n",
      "Mean Squared Log Error (MSLE): 0.1378\n",
      "\n",
      "Model performance metrics saved to 'nn_performance_metrics.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a99d10-e330-4980-910a-043c59b86378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Neural Network Model Setup ---\n",
    "        # Define a more complex sequential neural network model\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with 128 neurons and ReLU activation\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "        \n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer with 64 neurons and ReLU activation\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        \n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with more epochs\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=1000,  # Increased number of training epochs\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Save the Trained Model ---\n",
    "        # Save the entire model (architecture, weights, and optimizer state)\n",
    "        model_path = 'best_model.keras'\n",
    "        model.save(model_path)\n",
    "        print(f\"\\nModel saved successfully to '{model_path}'\")\n",
    "\n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        # Add a small epsilon to avoid division by zero\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        # Mean Squared Log Error (MSLE) - check for negative values\n",
    "        # Add a small value to predictions to avoid log(0)\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        # Create a dictionary to hold the metrics\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d524fe34-6f70-4861-b978-32f5a280fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\River-Flood-Prediction\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,113</span> (39.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,113\u001b[0m (39.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,113</span> (39.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,113\u001b[0m (39.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.5127 - loss: 0.7000 - val_accuracy: 0.5163 - val_loss: 0.6946\n",
      "Epoch 2/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5116 - loss: 0.6958 - val_accuracy: 0.5250 - val_loss: 0.6935\n",
      "Epoch 3/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5269 - loss: 0.6921 - val_accuracy: 0.5031 - val_loss: 0.6947\n",
      "Epoch 4/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5383 - loss: 0.6909 - val_accuracy: 0.5275 - val_loss: 0.6929\n",
      "Epoch 5/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5406 - loss: 0.6890 - val_accuracy: 0.5188 - val_loss: 0.6932\n",
      "Epoch 6/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5417 - loss: 0.6886 - val_accuracy: 0.5312 - val_loss: 0.6925\n",
      "Epoch 7/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5525 - loss: 0.6849 - val_accuracy: 0.5156 - val_loss: 0.6949\n",
      "Epoch 8/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5553 - loss: 0.6849 - val_accuracy: 0.5206 - val_loss: 0.6937\n",
      "Epoch 9/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5545 - loss: 0.6844 - val_accuracy: 0.5356 - val_loss: 0.6924\n",
      "Epoch 10/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5591 - loss: 0.6823 - val_accuracy: 0.5225 - val_loss: 0.6966\n",
      "Epoch 11/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5580 - loss: 0.6826 - val_accuracy: 0.5113 - val_loss: 0.6957\n",
      "Epoch 12/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5641 - loss: 0.6812 - val_accuracy: 0.5150 - val_loss: 0.6963\n",
      "Epoch 13/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5659 - loss: 0.6786 - val_accuracy: 0.5038 - val_loss: 0.7015\n",
      "Epoch 14/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.5677 - loss: 0.6803 - val_accuracy: 0.5106 - val_loss: 0.6968\n",
      "Epoch 15/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5709 - loss: 0.6782 - val_accuracy: 0.5113 - val_loss: 0.6962\n",
      "Epoch 16/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5719 - loss: 0.6788 - val_accuracy: 0.5094 - val_loss: 0.7003\n",
      "Epoch 17/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5781 - loss: 0.6757 - val_accuracy: 0.5075 - val_loss: 0.7009\n",
      "Epoch 18/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.5878 - loss: 0.6709 - val_accuracy: 0.5094 - val_loss: 0.7042\n",
      "Epoch 19/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5873 - loss: 0.6696 - val_accuracy: 0.5113 - val_loss: 0.7013\n",
      "Epoch 20/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5822 - loss: 0.6720 - val_accuracy: 0.5100 - val_loss: 0.7027\n",
      "Epoch 21/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.5916 - loss: 0.6685 - val_accuracy: 0.5131 - val_loss: 0.7047\n",
      "Epoch 22/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5903 - loss: 0.6677 - val_accuracy: 0.5106 - val_loss: 0.7043\n",
      "Epoch 23/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5920 - loss: 0.6662 - val_accuracy: 0.5056 - val_loss: 0.7101\n",
      "Epoch 24/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.5936 - loss: 0.6678 - val_accuracy: 0.5106 - val_loss: 0.7059\n",
      "Epoch 25/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6047 - loss: 0.6614 - val_accuracy: 0.5150 - val_loss: 0.7082\n",
      "Epoch 26/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6011 - loss: 0.6625 - val_accuracy: 0.5281 - val_loss: 0.7072\n",
      "Epoch 27/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.5973 - loss: 0.6639 - val_accuracy: 0.5163 - val_loss: 0.7054\n",
      "Epoch 28/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6100 - loss: 0.6592 - val_accuracy: 0.5025 - val_loss: 0.7131\n",
      "Epoch 29/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6078 - loss: 0.6601 - val_accuracy: 0.4950 - val_loss: 0.7161\n",
      "Epoch 30/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6048 - loss: 0.6604 - val_accuracy: 0.5019 - val_loss: 0.7148\n",
      "Epoch 31/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6030 - loss: 0.6599 - val_accuracy: 0.4956 - val_loss: 0.7152\n",
      "Epoch 32/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6017 - loss: 0.6569 - val_accuracy: 0.5081 - val_loss: 0.7147\n",
      "Epoch 33/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6111 - loss: 0.6579 - val_accuracy: 0.5044 - val_loss: 0.7140\n",
      "Epoch 34/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.6103 - loss: 0.6524 - val_accuracy: 0.5181 - val_loss: 0.7128\n",
      "Epoch 35/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6037 - loss: 0.6543 - val_accuracy: 0.5138 - val_loss: 0.7158\n",
      "Epoch 36/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6019 - loss: 0.6564 - val_accuracy: 0.5125 - val_loss: 0.7169\n",
      "Epoch 37/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6134 - loss: 0.6512 - val_accuracy: 0.5050 - val_loss: 0.7192\n",
      "Epoch 38/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6203 - loss: 0.6497 - val_accuracy: 0.5006 - val_loss: 0.7187\n",
      "Epoch 39/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6247 - loss: 0.6466 - val_accuracy: 0.5050 - val_loss: 0.7221\n",
      "Epoch 40/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6170 - loss: 0.6512 - val_accuracy: 0.5000 - val_loss: 0.7202\n",
      "Epoch 41/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6223 - loss: 0.6463 - val_accuracy: 0.5106 - val_loss: 0.7214\n",
      "Epoch 42/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6144 - loss: 0.6511 - val_accuracy: 0.4975 - val_loss: 0.7247\n",
      "Epoch 43/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6272 - loss: 0.6445 - val_accuracy: 0.4963 - val_loss: 0.7227\n",
      "Epoch 44/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6223 - loss: 0.6458 - val_accuracy: 0.5094 - val_loss: 0.7225\n",
      "Epoch 45/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6192 - loss: 0.6462 - val_accuracy: 0.5044 - val_loss: 0.7214\n",
      "Epoch 46/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6284 - loss: 0.6402 - val_accuracy: 0.5069 - val_loss: 0.7224\n",
      "Epoch 47/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6334 - loss: 0.6403 - val_accuracy: 0.5050 - val_loss: 0.7266\n",
      "Epoch 48/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6273 - loss: 0.6428 - val_accuracy: 0.4988 - val_loss: 0.7278\n",
      "Epoch 49/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6350 - loss: 0.6403 - val_accuracy: 0.4975 - val_loss: 0.7311\n",
      "Epoch 50/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6333 - loss: 0.6392 - val_accuracy: 0.4975 - val_loss: 0.7310\n",
      "Epoch 51/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6416 - loss: 0.6337 - val_accuracy: 0.5100 - val_loss: 0.7370\n",
      "Epoch 52/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6358 - loss: 0.6352 - val_accuracy: 0.5044 - val_loss: 0.7358\n",
      "Epoch 53/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6267 - loss: 0.6408 - val_accuracy: 0.5063 - val_loss: 0.7333\n",
      "Epoch 54/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6450 - loss: 0.6327 - val_accuracy: 0.5050 - val_loss: 0.7324\n",
      "Epoch 55/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6308 - loss: 0.6378 - val_accuracy: 0.5025 - val_loss: 0.7316\n",
      "Epoch 56/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6433 - loss: 0.6342 - val_accuracy: 0.5119 - val_loss: 0.7305\n",
      "Epoch 57/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6452 - loss: 0.6282 - val_accuracy: 0.5056 - val_loss: 0.7317\n",
      "Epoch 58/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6484 - loss: 0.6305 - val_accuracy: 0.4975 - val_loss: 0.7378\n",
      "Epoch 59/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 0.6272 - val_accuracy: 0.5019 - val_loss: 0.7375\n",
      "Epoch 60/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6472 - loss: 0.6237 - val_accuracy: 0.5050 - val_loss: 0.7430\n",
      "Epoch 61/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6423 - loss: 0.6251 - val_accuracy: 0.4994 - val_loss: 0.7398\n",
      "Epoch 62/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6439 - loss: 0.6312 - val_accuracy: 0.4981 - val_loss: 0.7462\n",
      "Epoch 63/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6472 - loss: 0.6251 - val_accuracy: 0.4913 - val_loss: 0.7423\n",
      "Epoch 64/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6495 - loss: 0.6239 - val_accuracy: 0.5000 - val_loss: 0.7410\n",
      "Epoch 65/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6409 - loss: 0.6290 - val_accuracy: 0.5013 - val_loss: 0.7437\n",
      "Epoch 66/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6505 - loss: 0.6230 - val_accuracy: 0.4988 - val_loss: 0.7415\n",
      "Epoch 67/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6517 - loss: 0.6201 - val_accuracy: 0.4969 - val_loss: 0.7433\n",
      "Epoch 68/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6542 - loss: 0.6178 - val_accuracy: 0.5044 - val_loss: 0.7450\n",
      "Epoch 69/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6569 - loss: 0.6173 - val_accuracy: 0.4994 - val_loss: 0.7458\n",
      "Epoch 70/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6569 - loss: 0.6187 - val_accuracy: 0.4944 - val_loss: 0.7490\n",
      "Epoch 71/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6570 - loss: 0.6177 - val_accuracy: 0.4950 - val_loss: 0.7555\n",
      "Epoch 72/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6547 - loss: 0.6220 - val_accuracy: 0.4906 - val_loss: 0.7533\n",
      "Epoch 73/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6594 - loss: 0.6147 - val_accuracy: 0.4906 - val_loss: 0.7528\n",
      "Epoch 74/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6517 - loss: 0.6169 - val_accuracy: 0.4994 - val_loss: 0.7531\n",
      "Epoch 75/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6581 - loss: 0.6173 - val_accuracy: 0.4950 - val_loss: 0.7594\n",
      "Epoch 76/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6558 - loss: 0.6194 - val_accuracy: 0.5013 - val_loss: 0.7484\n",
      "Epoch 77/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6581 - loss: 0.6180 - val_accuracy: 0.5019 - val_loss: 0.7584\n",
      "Epoch 78/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6620 - loss: 0.6091 - val_accuracy: 0.4938 - val_loss: 0.7629\n",
      "Epoch 79/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6659 - loss: 0.6093 - val_accuracy: 0.4875 - val_loss: 0.7582\n",
      "Epoch 80/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6552 - loss: 0.6138 - val_accuracy: 0.4875 - val_loss: 0.7627\n",
      "Epoch 81/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6655 - loss: 0.6056 - val_accuracy: 0.5038 - val_loss: 0.7591\n",
      "Epoch 82/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6698 - loss: 0.6070 - val_accuracy: 0.4913 - val_loss: 0.7611\n",
      "Epoch 83/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6630 - loss: 0.6096 - val_accuracy: 0.5000 - val_loss: 0.7654\n",
      "Epoch 84/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6697 - loss: 0.6086 - val_accuracy: 0.5006 - val_loss: 0.7597\n",
      "Epoch 85/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6666 - loss: 0.6060 - val_accuracy: 0.5006 - val_loss: 0.7596\n",
      "Epoch 86/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6658 - loss: 0.6082 - val_accuracy: 0.4963 - val_loss: 0.7677\n",
      "Epoch 87/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6645 - loss: 0.6047 - val_accuracy: 0.4963 - val_loss: 0.7634\n",
      "Epoch 88/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6698 - loss: 0.6044 - val_accuracy: 0.5044 - val_loss: 0.7620\n",
      "Epoch 89/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6667 - loss: 0.6044 - val_accuracy: 0.4694 - val_loss: 0.7773\n",
      "Epoch 90/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6664 - loss: 0.6042 - val_accuracy: 0.4812 - val_loss: 0.7732\n",
      "Epoch 91/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6627 - loss: 0.6030 - val_accuracy: 0.4913 - val_loss: 0.7704\n",
      "Epoch 92/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6762 - loss: 0.5969 - val_accuracy: 0.4837 - val_loss: 0.7724\n",
      "Epoch 93/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6764 - loss: 0.6007 - val_accuracy: 0.4875 - val_loss: 0.7732\n",
      "Epoch 94/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6844 - loss: 0.5919 - val_accuracy: 0.4931 - val_loss: 0.7722\n",
      "Epoch 95/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6825 - loss: 0.5959 - val_accuracy: 0.4850 - val_loss: 0.7803\n",
      "Epoch 96/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6866 - loss: 0.5942 - val_accuracy: 0.4781 - val_loss: 0.7849\n",
      "Epoch 97/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6772 - loss: 0.5924 - val_accuracy: 0.4906 - val_loss: 0.7749\n",
      "Epoch 98/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6784 - loss: 0.6025 - val_accuracy: 0.4931 - val_loss: 0.7737\n",
      "Epoch 99/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6753 - loss: 0.5959 - val_accuracy: 0.4906 - val_loss: 0.7741\n",
      "Epoch 100/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6806 - loss: 0.5939 - val_accuracy: 0.4888 - val_loss: 0.7771\n",
      "Epoch 101/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.5933 - val_accuracy: 0.4881 - val_loss: 0.7871\n",
      "Epoch 102/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6792 - loss: 0.5948 - val_accuracy: 0.4888 - val_loss: 0.7816\n",
      "Epoch 103/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6836 - loss: 0.5939 - val_accuracy: 0.4956 - val_loss: 0.7807\n",
      "Epoch 104/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6916 - loss: 0.5848 - val_accuracy: 0.4869 - val_loss: 0.7876\n",
      "Epoch 105/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6869 - loss: 0.5861 - val_accuracy: 0.4969 - val_loss: 0.7832\n",
      "Epoch 106/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6884 - loss: 0.5850 - val_accuracy: 0.4875 - val_loss: 0.7894\n",
      "Epoch 107/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6867 - loss: 0.5900 - val_accuracy: 0.4881 - val_loss: 0.8016\n",
      "Epoch 108/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6828 - loss: 0.5918 - val_accuracy: 0.4863 - val_loss: 0.7869\n",
      "Epoch 109/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 0.5884 - val_accuracy: 0.4888 - val_loss: 0.7794\n",
      "Epoch 110/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6884 - loss: 0.5851 - val_accuracy: 0.4888 - val_loss: 0.7867\n",
      "Epoch 111/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6895 - loss: 0.5815 - val_accuracy: 0.4844 - val_loss: 0.7937\n",
      "Epoch 112/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6839 - loss: 0.5843 - val_accuracy: 0.4975 - val_loss: 0.7857\n",
      "Epoch 113/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6914 - loss: 0.5804 - val_accuracy: 0.4806 - val_loss: 0.7950\n",
      "Epoch 114/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6802 - loss: 0.5918 - val_accuracy: 0.4806 - val_loss: 0.7939\n",
      "Epoch 115/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6909 - loss: 0.5826 - val_accuracy: 0.4894 - val_loss: 0.7860\n",
      "Epoch 116/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6877 - loss: 0.5886 - val_accuracy: 0.4888 - val_loss: 0.7916\n",
      "Epoch 117/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6873 - loss: 0.5838 - val_accuracy: 0.4812 - val_loss: 0.7929\n",
      "Epoch 118/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6869 - loss: 0.5867 - val_accuracy: 0.4919 - val_loss: 0.7957\n",
      "Epoch 119/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6931 - loss: 0.5830 - val_accuracy: 0.4919 - val_loss: 0.7878\n",
      "Epoch 120/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6953 - loss: 0.5833 - val_accuracy: 0.4831 - val_loss: 0.7954\n",
      "Epoch 121/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6967 - loss: 0.5789 - val_accuracy: 0.4919 - val_loss: 0.7981\n",
      "Epoch 122/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6889 - loss: 0.5860 - val_accuracy: 0.4844 - val_loss: 0.7931\n",
      "Epoch 123/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6925 - loss: 0.5818 - val_accuracy: 0.4781 - val_loss: 0.7958\n",
      "Epoch 124/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6983 - loss: 0.5757 - val_accuracy: 0.4812 - val_loss: 0.7938\n",
      "Epoch 125/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6930 - loss: 0.5765 - val_accuracy: 0.4938 - val_loss: 0.7947\n",
      "Epoch 126/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6927 - loss: 0.5790 - val_accuracy: 0.4888 - val_loss: 0.7946\n",
      "Epoch 127/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6884 - loss: 0.5813 - val_accuracy: 0.4831 - val_loss: 0.7937\n",
      "Epoch 128/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6938 - loss: 0.5801 - val_accuracy: 0.4875 - val_loss: 0.7956\n",
      "Epoch 129/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6891 - loss: 0.5752 - val_accuracy: 0.4781 - val_loss: 0.8009\n",
      "Epoch 130/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6878 - loss: 0.5738 - val_accuracy: 0.4888 - val_loss: 0.8045\n",
      "Epoch 131/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.5747 - val_accuracy: 0.4963 - val_loss: 0.8002\n",
      "Epoch 132/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7016 - loss: 0.5707 - val_accuracy: 0.4888 - val_loss: 0.8036\n",
      "Epoch 133/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6923 - loss: 0.5717 - val_accuracy: 0.4888 - val_loss: 0.8091\n",
      "Epoch 134/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6986 - loss: 0.5673 - val_accuracy: 0.4956 - val_loss: 0.8078\n",
      "Epoch 135/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.5753 - val_accuracy: 0.4794 - val_loss: 0.8058\n",
      "Epoch 136/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7034 - loss: 0.5699 - val_accuracy: 0.4787 - val_loss: 0.8100\n",
      "Epoch 137/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6908 - loss: 0.5748 - val_accuracy: 0.4850 - val_loss: 0.7994\n",
      "Epoch 138/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.5653 - val_accuracy: 0.4844 - val_loss: 0.8045\n",
      "Epoch 139/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7069 - loss: 0.5699 - val_accuracy: 0.4875 - val_loss: 0.8065\n",
      "Epoch 140/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6903 - loss: 0.5721 - val_accuracy: 0.4731 - val_loss: 0.8113\n",
      "Epoch 141/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6958 - loss: 0.5750 - val_accuracy: 0.4719 - val_loss: 0.8119\n",
      "Epoch 142/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7052 - loss: 0.5656 - val_accuracy: 0.4856 - val_loss: 0.8084\n",
      "Epoch 143/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7044 - loss: 0.5646 - val_accuracy: 0.4875 - val_loss: 0.8106\n",
      "Epoch 144/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7000 - loss: 0.5726 - val_accuracy: 0.4825 - val_loss: 0.8080\n",
      "Epoch 145/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7016 - loss: 0.5691 - val_accuracy: 0.4769 - val_loss: 0.8125\n",
      "Epoch 146/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7038 - loss: 0.5681 - val_accuracy: 0.4906 - val_loss: 0.8127\n",
      "Epoch 147/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7014 - loss: 0.5694 - val_accuracy: 0.4775 - val_loss: 0.8133\n",
      "Epoch 148/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.5679 - val_accuracy: 0.4831 - val_loss: 0.8165\n",
      "Epoch 149/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7077 - loss: 0.5561 - val_accuracy: 0.4938 - val_loss: 0.8107\n",
      "Epoch 150/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7080 - loss: 0.5668 - val_accuracy: 0.4787 - val_loss: 0.8099\n",
      "Epoch 151/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.5701 - val_accuracy: 0.4756 - val_loss: 0.8104\n",
      "Epoch 152/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7014 - loss: 0.5636 - val_accuracy: 0.4781 - val_loss: 0.8148\n",
      "Epoch 153/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7072 - loss: 0.5614 - val_accuracy: 0.4787 - val_loss: 0.8200\n",
      "Epoch 154/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7103 - loss: 0.5608 - val_accuracy: 0.4819 - val_loss: 0.8109\n",
      "Epoch 155/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7081 - loss: 0.5675 - val_accuracy: 0.4856 - val_loss: 0.8148\n",
      "Epoch 156/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7117 - loss: 0.5612 - val_accuracy: 0.4869 - val_loss: 0.8146\n",
      "Epoch 157/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7134 - loss: 0.5560 - val_accuracy: 0.4787 - val_loss: 0.8193\n",
      "Epoch 158/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7058 - loss: 0.5679 - val_accuracy: 0.4869 - val_loss: 0.8164\n",
      "Epoch 159/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7052 - loss: 0.5612 - val_accuracy: 0.4800 - val_loss: 0.8202\n",
      "Epoch 160/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7134 - loss: 0.5484 - val_accuracy: 0.4825 - val_loss: 0.8198\n",
      "Epoch 161/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7067 - loss: 0.5606 - val_accuracy: 0.4794 - val_loss: 0.8216\n",
      "Epoch 162/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7141 - loss: 0.5626 - val_accuracy: 0.4794 - val_loss: 0.8219\n",
      "Epoch 163/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7170 - loss: 0.5510 - val_accuracy: 0.4837 - val_loss: 0.8172\n",
      "Epoch 164/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7119 - loss: 0.5578 - val_accuracy: 0.4963 - val_loss: 0.8166\n",
      "Epoch 165/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7127 - loss: 0.5508 - val_accuracy: 0.4775 - val_loss: 0.8285\n",
      "Epoch 166/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 0.5612 - val_accuracy: 0.4844 - val_loss: 0.8209\n",
      "Epoch 167/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.5608 - val_accuracy: 0.4706 - val_loss: 0.8318\n",
      "Epoch 168/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7161 - loss: 0.5520 - val_accuracy: 0.4800 - val_loss: 0.8285\n",
      "Epoch 169/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.5585 - val_accuracy: 0.4819 - val_loss: 0.8302\n",
      "Epoch 170/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7097 - loss: 0.5547 - val_accuracy: 0.4781 - val_loss: 0.8289\n",
      "Epoch 171/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7036 - loss: 0.5570 - val_accuracy: 0.4781 - val_loss: 0.8342\n",
      "Epoch 172/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7117 - loss: 0.5530 - val_accuracy: 0.4831 - val_loss: 0.8248\n",
      "Epoch 173/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7191 - loss: 0.5471 - val_accuracy: 0.4769 - val_loss: 0.8219\n",
      "Epoch 174/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7128 - loss: 0.5528 - val_accuracy: 0.4700 - val_loss: 0.8306\n",
      "Epoch 175/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7122 - loss: 0.5546 - val_accuracy: 0.4769 - val_loss: 0.8238\n",
      "Epoch 176/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7183 - loss: 0.5452 - val_accuracy: 0.4925 - val_loss: 0.8309\n",
      "Epoch 177/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7164 - loss: 0.5564 - val_accuracy: 0.4800 - val_loss: 0.8269\n",
      "Epoch 178/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7191 - loss: 0.5442 - val_accuracy: 0.4919 - val_loss: 0.8271\n",
      "Epoch 179/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7239 - loss: 0.5487 - val_accuracy: 0.4787 - val_loss: 0.8318\n",
      "Epoch 180/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7130 - loss: 0.5559 - val_accuracy: 0.4863 - val_loss: 0.8354\n",
      "Epoch 181/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7141 - loss: 0.5552 - val_accuracy: 0.4794 - val_loss: 0.8341\n",
      "Epoch 182/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7128 - loss: 0.5486 - val_accuracy: 0.4731 - val_loss: 0.8384\n",
      "Epoch 183/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7166 - loss: 0.5485 - val_accuracy: 0.4719 - val_loss: 0.8373\n",
      "Epoch 184/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7230 - loss: 0.5460 - val_accuracy: 0.4712 - val_loss: 0.8383\n",
      "Epoch 185/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7205 - loss: 0.5463 - val_accuracy: 0.4794 - val_loss: 0.8414\n",
      "Epoch 186/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7169 - loss: 0.5505 - val_accuracy: 0.4894 - val_loss: 0.8323\n",
      "Epoch 187/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7172 - loss: 0.5417 - val_accuracy: 0.4800 - val_loss: 0.8380\n",
      "Epoch 188/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7205 - loss: 0.5459 - val_accuracy: 0.4831 - val_loss: 0.8292\n",
      "Epoch 189/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7161 - loss: 0.5486 - val_accuracy: 0.4856 - val_loss: 0.8386\n",
      "Epoch 190/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7083 - loss: 0.5512 - val_accuracy: 0.4869 - val_loss: 0.8328\n",
      "Epoch 191/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7172 - loss: 0.5442 - val_accuracy: 0.4850 - val_loss: 0.8320\n",
      "Epoch 192/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7172 - loss: 0.5474 - val_accuracy: 0.4800 - val_loss: 0.8370\n",
      "Epoch 193/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7261 - loss: 0.5384 - val_accuracy: 0.4869 - val_loss: 0.8372\n",
      "Epoch 194/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7250 - loss: 0.5429 - val_accuracy: 0.4819 - val_loss: 0.8433\n",
      "Epoch 195/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7147 - loss: 0.5455 - val_accuracy: 0.4775 - val_loss: 0.8378\n",
      "Epoch 196/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7133 - loss: 0.5470 - val_accuracy: 0.4819 - val_loss: 0.8440\n",
      "Epoch 197/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7172 - loss: 0.5472 - val_accuracy: 0.4888 - val_loss: 0.8443\n",
      "Epoch 198/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7209 - loss: 0.5431 - val_accuracy: 0.4681 - val_loss: 0.8407\n",
      "Epoch 199/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7273 - loss: 0.5471 - val_accuracy: 0.4719 - val_loss: 0.8519\n",
      "Epoch 200/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7242 - loss: 0.5398 - val_accuracy: 0.4725 - val_loss: 0.8491\n",
      "Epoch 201/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7178 - loss: 0.5441 - val_accuracy: 0.4744 - val_loss: 0.8467\n",
      "Epoch 202/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7189 - loss: 0.5478 - val_accuracy: 0.4725 - val_loss: 0.8505\n",
      "Epoch 203/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7258 - loss: 0.5353 - val_accuracy: 0.4800 - val_loss: 0.8461\n",
      "Epoch 204/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7109 - loss: 0.5470 - val_accuracy: 0.4775 - val_loss: 0.8571\n",
      "Epoch 205/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7259 - loss: 0.5397 - val_accuracy: 0.4744 - val_loss: 0.8523\n",
      "Epoch 206/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7311 - loss: 0.5299 - val_accuracy: 0.4794 - val_loss: 0.8636\n",
      "Epoch 207/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7272 - loss: 0.5346 - val_accuracy: 0.4850 - val_loss: 0.8628\n",
      "Epoch 208/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7222 - loss: 0.5364 - val_accuracy: 0.4781 - val_loss: 0.8627\n",
      "Epoch 209/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7231 - loss: 0.5382 - val_accuracy: 0.4794 - val_loss: 0.8538\n",
      "Epoch 210/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7194 - loss: 0.5407 - val_accuracy: 0.4850 - val_loss: 0.8494\n",
      "Epoch 211/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7303 - loss: 0.5345 - val_accuracy: 0.4900 - val_loss: 0.8499\n",
      "Epoch 212/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7250 - loss: 0.5389 - val_accuracy: 0.4787 - val_loss: 0.8493\n",
      "Epoch 213/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.5382 - val_accuracy: 0.4944 - val_loss: 0.8432\n",
      "Epoch 214/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7297 - loss: 0.5355 - val_accuracy: 0.4850 - val_loss: 0.8505\n",
      "Epoch 215/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7183 - loss: 0.5399 - val_accuracy: 0.4875 - val_loss: 0.8516\n",
      "Epoch 216/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7323 - loss: 0.5371 - val_accuracy: 0.4812 - val_loss: 0.8509\n",
      "Epoch 217/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7234 - loss: 0.5379 - val_accuracy: 0.4787 - val_loss: 0.8517\n",
      "Epoch 218/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7303 - loss: 0.5303 - val_accuracy: 0.4863 - val_loss: 0.8530\n",
      "Epoch 219/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7306 - loss: 0.5341 - val_accuracy: 0.4750 - val_loss: 0.8551\n",
      "Epoch 220/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7245 - loss: 0.5387 - val_accuracy: 0.4762 - val_loss: 0.8536\n",
      "Epoch 221/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7233 - loss: 0.5321 - val_accuracy: 0.4762 - val_loss: 0.8661\n",
      "Epoch 222/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7247 - loss: 0.5354 - val_accuracy: 0.4819 - val_loss: 0.8605\n",
      "Epoch 223/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7305 - loss: 0.5312 - val_accuracy: 0.4794 - val_loss: 0.8563\n",
      "Epoch 224/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7270 - loss: 0.5367 - val_accuracy: 0.4863 - val_loss: 0.8540\n",
      "Epoch 225/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7297 - loss: 0.5336 - val_accuracy: 0.4844 - val_loss: 0.8620\n",
      "Epoch 226/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7316 - loss: 0.5318 - val_accuracy: 0.4787 - val_loss: 0.8577\n",
      "Epoch 227/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7266 - loss: 0.5377 - val_accuracy: 0.4769 - val_loss: 0.8640\n",
      "Epoch 228/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7256 - loss: 0.5315 - val_accuracy: 0.4806 - val_loss: 0.8598\n",
      "Epoch 229/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7419 - loss: 0.5290 - val_accuracy: 0.4794 - val_loss: 0.8534\n",
      "Epoch 230/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7314 - loss: 0.5320 - val_accuracy: 0.4812 - val_loss: 0.8547\n",
      "Epoch 231/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7280 - loss: 0.5301 - val_accuracy: 0.4781 - val_loss: 0.8685\n",
      "Epoch 232/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7241 - loss: 0.5373 - val_accuracy: 0.4819 - val_loss: 0.8640\n",
      "Epoch 233/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7312 - loss: 0.5250 - val_accuracy: 0.4756 - val_loss: 0.8589\n",
      "Epoch 234/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7275 - loss: 0.5298 - val_accuracy: 0.4831 - val_loss: 0.8707\n",
      "Epoch 235/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7456 - loss: 0.5185 - val_accuracy: 0.4869 - val_loss: 0.8666\n",
      "Epoch 236/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7289 - loss: 0.5299 - val_accuracy: 0.4888 - val_loss: 0.8721\n",
      "Epoch 237/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7352 - loss: 0.5295 - val_accuracy: 0.4756 - val_loss: 0.8595\n",
      "Epoch 238/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7372 - loss: 0.5280 - val_accuracy: 0.4812 - val_loss: 0.8572\n",
      "Epoch 239/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7377 - loss: 0.5200 - val_accuracy: 0.4762 - val_loss: 0.8631\n",
      "Epoch 240/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7350 - loss: 0.5292 - val_accuracy: 0.4825 - val_loss: 0.8619\n",
      "Epoch 241/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7355 - loss: 0.5293 - val_accuracy: 0.4825 - val_loss: 0.8680\n",
      "Epoch 242/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7239 - loss: 0.5357 - val_accuracy: 0.4925 - val_loss: 0.8601\n",
      "Epoch 243/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7420 - loss: 0.5235 - val_accuracy: 0.4900 - val_loss: 0.8625\n",
      "Epoch 244/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7306 - loss: 0.5269 - val_accuracy: 0.4906 - val_loss: 0.8647\n",
      "Epoch 245/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7322 - loss: 0.5310 - val_accuracy: 0.4888 - val_loss: 0.8632\n",
      "Epoch 246/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7294 - loss: 0.5255 - val_accuracy: 0.4969 - val_loss: 0.8596\n",
      "Epoch 247/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7256 - loss: 0.5327 - val_accuracy: 0.4881 - val_loss: 0.8590\n",
      "Epoch 248/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7287 - loss: 0.5282 - val_accuracy: 0.4881 - val_loss: 0.8606\n",
      "Epoch 249/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7334 - loss: 0.5245 - val_accuracy: 0.4944 - val_loss: 0.8549\n",
      "Epoch 250/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7356 - loss: 0.5235 - val_accuracy: 0.4888 - val_loss: 0.8680\n",
      "Epoch 251/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7362 - loss: 0.5211 - val_accuracy: 0.4969 - val_loss: 0.8639\n",
      "Epoch 252/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7359 - loss: 0.5276 - val_accuracy: 0.4931 - val_loss: 0.8662\n",
      "Epoch 253/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7286 - loss: 0.5281 - val_accuracy: 0.4981 - val_loss: 0.8714\n",
      "Epoch 254/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7337 - loss: 0.5251 - val_accuracy: 0.5031 - val_loss: 0.8671\n",
      "Epoch 255/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7370 - loss: 0.5191 - val_accuracy: 0.4844 - val_loss: 0.8758\n",
      "Epoch 256/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7303 - loss: 0.5210 - val_accuracy: 0.4944 - val_loss: 0.8685\n",
      "Epoch 257/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7319 - loss: 0.5281 - val_accuracy: 0.4888 - val_loss: 0.8593\n",
      "Epoch 258/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7333 - loss: 0.5233 - val_accuracy: 0.4944 - val_loss: 0.8653\n",
      "Epoch 259/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7336 - loss: 0.5275 - val_accuracy: 0.4894 - val_loss: 0.8683\n",
      "Epoch 260/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7398 - loss: 0.5208 - val_accuracy: 0.4925 - val_loss: 0.8704\n",
      "Epoch 261/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7412 - loss: 0.5177 - val_accuracy: 0.4894 - val_loss: 0.8784\n",
      "Epoch 262/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7403 - loss: 0.5199 - val_accuracy: 0.4944 - val_loss: 0.8679\n",
      "Epoch 263/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7436 - loss: 0.5107 - val_accuracy: 0.4913 - val_loss: 0.8683\n",
      "Epoch 264/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7297 - loss: 0.5299 - val_accuracy: 0.5038 - val_loss: 0.8599\n",
      "Epoch 265/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7475 - loss: 0.5153 - val_accuracy: 0.4925 - val_loss: 0.8737\n",
      "Epoch 266/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7350 - loss: 0.5254 - val_accuracy: 0.4931 - val_loss: 0.8719\n",
      "Epoch 267/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7412 - loss: 0.5182 - val_accuracy: 0.4938 - val_loss: 0.8782\n",
      "Epoch 268/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7417 - loss: 0.5128 - val_accuracy: 0.4787 - val_loss: 0.8753\n",
      "Epoch 269/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7434 - loss: 0.5147 - val_accuracy: 0.4794 - val_loss: 0.8822\n",
      "Epoch 270/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7383 - loss: 0.5222 - val_accuracy: 0.4894 - val_loss: 0.8767\n",
      "Epoch 271/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7386 - loss: 0.5164 - val_accuracy: 0.4938 - val_loss: 0.8885\n",
      "Epoch 272/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7422 - loss: 0.5157 - val_accuracy: 0.4825 - val_loss: 0.8877\n",
      "Epoch 273/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7423 - loss: 0.5167 - val_accuracy: 0.4825 - val_loss: 0.8875\n",
      "Epoch 274/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7408 - loss: 0.5146 - val_accuracy: 0.4844 - val_loss: 0.8861\n",
      "Epoch 275/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7437 - loss: 0.5070 - val_accuracy: 0.4787 - val_loss: 0.8796\n",
      "Epoch 276/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7444 - loss: 0.5143 - val_accuracy: 0.4875 - val_loss: 0.8865\n",
      "Epoch 277/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7400 - loss: 0.5157 - val_accuracy: 0.4800 - val_loss: 0.8905\n",
      "Epoch 278/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7353 - loss: 0.5240 - val_accuracy: 0.4869 - val_loss: 0.8823\n",
      "Epoch 279/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7370 - loss: 0.5238 - val_accuracy: 0.4812 - val_loss: 0.8719\n",
      "Epoch 280/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7272 - loss: 0.5257 - val_accuracy: 0.4881 - val_loss: 0.8710\n",
      "Epoch 281/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7511 - loss: 0.5080 - val_accuracy: 0.4925 - val_loss: 0.8732\n",
      "Epoch 282/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7447 - loss: 0.5146 - val_accuracy: 0.4913 - val_loss: 0.8722\n",
      "Epoch 283/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7544 - loss: 0.5017 - val_accuracy: 0.4881 - val_loss: 0.8735\n",
      "Epoch 284/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7452 - loss: 0.5093 - val_accuracy: 0.4875 - val_loss: 0.8758\n",
      "Epoch 285/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7439 - loss: 0.5150 - val_accuracy: 0.4837 - val_loss: 0.8809\n",
      "Epoch 286/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7402 - loss: 0.5225 - val_accuracy: 0.4837 - val_loss: 0.8883\n",
      "Epoch 287/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7423 - loss: 0.5177 - val_accuracy: 0.4900 - val_loss: 0.8847\n",
      "Epoch 288/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7447 - loss: 0.5157 - val_accuracy: 0.4956 - val_loss: 0.8776\n",
      "Epoch 289/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7431 - loss: 0.5089 - val_accuracy: 0.4956 - val_loss: 0.8868\n",
      "Epoch 290/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7450 - loss: 0.5059 - val_accuracy: 0.4856 - val_loss: 0.8960\n",
      "Epoch 291/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7428 - loss: 0.5135 - val_accuracy: 0.4856 - val_loss: 0.8966\n",
      "Epoch 292/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7392 - loss: 0.5267 - val_accuracy: 0.4888 - val_loss: 0.8826\n",
      "Epoch 293/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7412 - loss: 0.5189 - val_accuracy: 0.4863 - val_loss: 0.8876\n",
      "Epoch 294/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7466 - loss: 0.5089 - val_accuracy: 0.4906 - val_loss: 0.8839\n",
      "Epoch 295/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7497 - loss: 0.5141 - val_accuracy: 0.4969 - val_loss: 0.8839\n",
      "Epoch 296/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7347 - loss: 0.5200 - val_accuracy: 0.4875 - val_loss: 0.8788\n",
      "Epoch 297/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7547 - loss: 0.5028 - val_accuracy: 0.4913 - val_loss: 0.8896\n",
      "Epoch 298/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7342 - loss: 0.5205 - val_accuracy: 0.4881 - val_loss: 0.8890\n",
      "Epoch 299/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7519 - loss: 0.5085 - val_accuracy: 0.4762 - val_loss: 0.8904\n",
      "Epoch 300/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7386 - loss: 0.5115 - val_accuracy: 0.4881 - val_loss: 0.8925\n",
      "Epoch 301/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7419 - loss: 0.5167 - val_accuracy: 0.4875 - val_loss: 0.8874\n",
      "Epoch 302/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7475 - loss: 0.5122 - val_accuracy: 0.4894 - val_loss: 0.8811\n",
      "Epoch 303/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7531 - loss: 0.4996 - val_accuracy: 0.4956 - val_loss: 0.8949\n",
      "Epoch 304/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7361 - loss: 0.5204 - val_accuracy: 0.4844 - val_loss: 0.8855\n",
      "Epoch 305/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7494 - loss: 0.5109 - val_accuracy: 0.4800 - val_loss: 0.8860\n",
      "Epoch 306/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7389 - loss: 0.5175 - val_accuracy: 0.4825 - val_loss: 0.8802\n",
      "Epoch 307/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7416 - loss: 0.5125 - val_accuracy: 0.4863 - val_loss: 0.8902\n",
      "Epoch 308/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7431 - loss: 0.5137 - val_accuracy: 0.4856 - val_loss: 0.8952\n",
      "Epoch 309/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7398 - loss: 0.5137 - val_accuracy: 0.4925 - val_loss: 0.8935\n",
      "Epoch 310/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7516 - loss: 0.5057 - val_accuracy: 0.4931 - val_loss: 0.8967\n",
      "Epoch 311/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7456 - loss: 0.5082 - val_accuracy: 0.4900 - val_loss: 0.8881\n",
      "Epoch 312/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7486 - loss: 0.5161 - val_accuracy: 0.4925 - val_loss: 0.8887\n",
      "Epoch 313/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7444 - loss: 0.5093 - val_accuracy: 0.4963 - val_loss: 0.8873\n",
      "Epoch 314/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7458 - loss: 0.5074 - val_accuracy: 0.4938 - val_loss: 0.8921\n",
      "Epoch 315/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7483 - loss: 0.5101 - val_accuracy: 0.4906 - val_loss: 0.8954\n",
      "Epoch 316/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7389 - loss: 0.5155 - val_accuracy: 0.4844 - val_loss: 0.8865\n",
      "Epoch 317/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7578 - loss: 0.5014 - val_accuracy: 0.4888 - val_loss: 0.8812\n",
      "Epoch 318/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7553 - loss: 0.5037 - val_accuracy: 0.4956 - val_loss: 0.8861\n",
      "Epoch 319/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7523 - loss: 0.5017 - val_accuracy: 0.4975 - val_loss: 0.8868\n",
      "Epoch 320/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7486 - loss: 0.5025 - val_accuracy: 0.4931 - val_loss: 0.8917\n",
      "Epoch 321/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7436 - loss: 0.5086 - val_accuracy: 0.4900 - val_loss: 0.8852\n",
      "Epoch 322/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7533 - loss: 0.4965 - val_accuracy: 0.4913 - val_loss: 0.8879\n",
      "Epoch 323/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7439 - loss: 0.5111 - val_accuracy: 0.4919 - val_loss: 0.8843\n",
      "Epoch 324/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7519 - loss: 0.5053 - val_accuracy: 0.4919 - val_loss: 0.8907\n",
      "Epoch 325/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7497 - loss: 0.5047 - val_accuracy: 0.4894 - val_loss: 0.8898\n",
      "Epoch 326/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7555 - loss: 0.5042 - val_accuracy: 0.4806 - val_loss: 0.8932\n",
      "Epoch 327/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7417 - loss: 0.5129 - val_accuracy: 0.4938 - val_loss: 0.8929\n",
      "Epoch 328/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7467 - loss: 0.5085 - val_accuracy: 0.4950 - val_loss: 0.8861\n",
      "Epoch 329/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7516 - loss: 0.5094 - val_accuracy: 0.4825 - val_loss: 0.8924\n",
      "Epoch 330/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7506 - loss: 0.5071 - val_accuracy: 0.4850 - val_loss: 0.8903\n",
      "Epoch 331/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7505 - loss: 0.5049 - val_accuracy: 0.4881 - val_loss: 0.8875\n",
      "Epoch 332/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7494 - loss: 0.5014 - val_accuracy: 0.4894 - val_loss: 0.8947\n",
      "Epoch 333/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7555 - loss: 0.4970 - val_accuracy: 0.4894 - val_loss: 0.8975\n",
      "Epoch 334/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7552 - loss: 0.5003 - val_accuracy: 0.4919 - val_loss: 0.8958\n",
      "Epoch 335/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7536 - loss: 0.5100 - val_accuracy: 0.4919 - val_loss: 0.8945\n",
      "Epoch 336/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7500 - loss: 0.5108 - val_accuracy: 0.4875 - val_loss: 0.8872\n",
      "Epoch 337/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7464 - loss: 0.5066 - val_accuracy: 0.4913 - val_loss: 0.8916\n",
      "Epoch 338/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7597 - loss: 0.4929 - val_accuracy: 0.4931 - val_loss: 0.8854\n",
      "Epoch 339/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7498 - loss: 0.5039 - val_accuracy: 0.4850 - val_loss: 0.8938\n",
      "Epoch 340/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7425 - loss: 0.5120 - val_accuracy: 0.4769 - val_loss: 0.8907\n",
      "Epoch 341/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7508 - loss: 0.5005 - val_accuracy: 0.4762 - val_loss: 0.9016\n",
      "Epoch 342/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7520 - loss: 0.5027 - val_accuracy: 0.4831 - val_loss: 0.9016\n",
      "Epoch 343/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7489 - loss: 0.5037 - val_accuracy: 0.4800 - val_loss: 0.8930\n",
      "Epoch 344/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7564 - loss: 0.4967 - val_accuracy: 0.4894 - val_loss: 0.8996\n",
      "Epoch 345/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7553 - loss: 0.4955 - val_accuracy: 0.4919 - val_loss: 0.9060\n",
      "Epoch 346/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7598 - loss: 0.4966 - val_accuracy: 0.4819 - val_loss: 0.9023\n",
      "Epoch 347/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7405 - loss: 0.5103 - val_accuracy: 0.4888 - val_loss: 0.8980\n",
      "Epoch 348/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7509 - loss: 0.4975 - val_accuracy: 0.4863 - val_loss: 0.9041\n",
      "Epoch 349/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7489 - loss: 0.5113 - val_accuracy: 0.4863 - val_loss: 0.9008\n",
      "Epoch 350/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7525 - loss: 0.5005 - val_accuracy: 0.4981 - val_loss: 0.8913\n",
      "Epoch 351/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7639 - loss: 0.4979 - val_accuracy: 0.4875 - val_loss: 0.9040\n",
      "Epoch 352/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7417 - loss: 0.5151 - val_accuracy: 0.4869 - val_loss: 0.8954\n",
      "Epoch 353/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7475 - loss: 0.5088 - val_accuracy: 0.4863 - val_loss: 0.8936\n",
      "Epoch 354/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7464 - loss: 0.5127 - val_accuracy: 0.4869 - val_loss: 0.8914\n",
      "Epoch 355/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7581 - loss: 0.4992 - val_accuracy: 0.4906 - val_loss: 0.8985\n",
      "Epoch 356/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7497 - loss: 0.5006 - val_accuracy: 0.4906 - val_loss: 0.8950\n",
      "Epoch 357/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7595 - loss: 0.4930 - val_accuracy: 0.4975 - val_loss: 0.9055\n",
      "Epoch 358/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.5047 - val_accuracy: 0.4850 - val_loss: 0.9035\n",
      "Epoch 359/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7631 - loss: 0.4916 - val_accuracy: 0.4831 - val_loss: 0.8997\n",
      "Epoch 360/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7513 - loss: 0.4949 - val_accuracy: 0.4963 - val_loss: 0.8984\n",
      "Epoch 361/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7527 - loss: 0.4958 - val_accuracy: 0.4975 - val_loss: 0.9017\n",
      "Epoch 362/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7569 - loss: 0.4980 - val_accuracy: 0.4856 - val_loss: 0.9021\n",
      "Epoch 363/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7539 - loss: 0.5001 - val_accuracy: 0.4931 - val_loss: 0.8958\n",
      "Epoch 364/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7530 - loss: 0.4988 - val_accuracy: 0.4944 - val_loss: 0.9013\n",
      "Epoch 365/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7595 - loss: 0.4856 - val_accuracy: 0.4956 - val_loss: 0.8937\n",
      "Epoch 366/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7517 - loss: 0.5045 - val_accuracy: 0.4956 - val_loss: 0.8961\n",
      "Epoch 367/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7517 - loss: 0.5021 - val_accuracy: 0.4925 - val_loss: 0.9003\n",
      "Epoch 368/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7627 - loss: 0.4896 - val_accuracy: 0.4837 - val_loss: 0.9138\n",
      "Epoch 369/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7481 - loss: 0.5055 - val_accuracy: 0.4888 - val_loss: 0.9145\n",
      "Epoch 370/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7520 - loss: 0.4991 - val_accuracy: 0.4869 - val_loss: 0.9067\n",
      "Epoch 371/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7538 - loss: 0.5012 - val_accuracy: 0.4888 - val_loss: 0.9138\n",
      "Epoch 372/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7487 - loss: 0.5044 - val_accuracy: 0.4956 - val_loss: 0.9018\n",
      "Epoch 373/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7597 - loss: 0.4975 - val_accuracy: 0.4850 - val_loss: 0.9050\n",
      "Epoch 374/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7577 - loss: 0.4899 - val_accuracy: 0.4956 - val_loss: 0.9034\n",
      "Epoch 375/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7614 - loss: 0.4961 - val_accuracy: 0.4906 - val_loss: 0.9042\n",
      "Epoch 376/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7581 - loss: 0.4998 - val_accuracy: 0.4869 - val_loss: 0.9175\n",
      "Epoch 377/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.7481 - loss: 0.5036 - val_accuracy: 0.4925 - val_loss: 0.9090\n",
      "Epoch 378/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7528 - loss: 0.4981 - val_accuracy: 0.4825 - val_loss: 0.9100\n",
      "Epoch 379/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7517 - loss: 0.5010 - val_accuracy: 0.4837 - val_loss: 0.8974\n",
      "Epoch 380/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7520 - loss: 0.4978 - val_accuracy: 0.4869 - val_loss: 0.8990\n",
      "Epoch 381/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7631 - loss: 0.4928 - val_accuracy: 0.4806 - val_loss: 0.9065\n",
      "Epoch 382/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7545 - loss: 0.5002 - val_accuracy: 0.4806 - val_loss: 0.9102\n",
      "Epoch 383/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7609 - loss: 0.4838 - val_accuracy: 0.4812 - val_loss: 0.9102\n",
      "Epoch 384/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7573 - loss: 0.4877 - val_accuracy: 0.4850 - val_loss: 0.9195\n",
      "Epoch 385/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7448 - loss: 0.4987 - val_accuracy: 0.4906 - val_loss: 0.9038\n",
      "Epoch 386/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7541 - loss: 0.5018 - val_accuracy: 0.4781 - val_loss: 0.9097\n",
      "Epoch 387/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7498 - loss: 0.5000 - val_accuracy: 0.4781 - val_loss: 0.9177\n",
      "Epoch 388/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7523 - loss: 0.4944 - val_accuracy: 0.4781 - val_loss: 0.9202\n",
      "Epoch 389/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7616 - loss: 0.4946 - val_accuracy: 0.4925 - val_loss: 0.9136\n",
      "Epoch 390/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7580 - loss: 0.5000 - val_accuracy: 0.4850 - val_loss: 0.9174\n",
      "Epoch 391/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7494 - loss: 0.4972 - val_accuracy: 0.4775 - val_loss: 0.9188\n",
      "Epoch 392/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7625 - loss: 0.4941 - val_accuracy: 0.4881 - val_loss: 0.9117\n",
      "Epoch 393/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7566 - loss: 0.4927 - val_accuracy: 0.4875 - val_loss: 0.9135\n",
      "Epoch 394/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7613 - loss: 0.4944 - val_accuracy: 0.4944 - val_loss: 0.9115\n",
      "Epoch 395/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7558 - loss: 0.4982 - val_accuracy: 0.4931 - val_loss: 0.9257\n",
      "Epoch 396/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7430 - loss: 0.5087 - val_accuracy: 0.4844 - val_loss: 0.9114\n",
      "Epoch 397/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7631 - loss: 0.4966 - val_accuracy: 0.4775 - val_loss: 0.9141\n",
      "Epoch 398/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7683 - loss: 0.4858 - val_accuracy: 0.4863 - val_loss: 0.9097\n",
      "Epoch 399/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7633 - loss: 0.4854 - val_accuracy: 0.4806 - val_loss: 0.9142\n",
      "Epoch 400/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7605 - loss: 0.4935 - val_accuracy: 0.4800 - val_loss: 0.9121\n",
      "Epoch 401/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7547 - loss: 0.4971 - val_accuracy: 0.4869 - val_loss: 0.9175\n",
      "Epoch 402/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7570 - loss: 0.4920 - val_accuracy: 0.4806 - val_loss: 0.9156\n",
      "Epoch 403/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7663 - loss: 0.4867 - val_accuracy: 0.4800 - val_loss: 0.9104\n",
      "Epoch 404/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7597 - loss: 0.4894 - val_accuracy: 0.4812 - val_loss: 0.9119\n",
      "Epoch 405/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7536 - loss: 0.4938 - val_accuracy: 0.4731 - val_loss: 0.9115\n",
      "Epoch 406/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7569 - loss: 0.4913 - val_accuracy: 0.4869 - val_loss: 0.9115\n",
      "Epoch 407/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7653 - loss: 0.4861 - val_accuracy: 0.4837 - val_loss: 0.9119\n",
      "Epoch 408/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7627 - loss: 0.4908 - val_accuracy: 0.4806 - val_loss: 0.9248\n",
      "Epoch 409/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7620 - loss: 0.4903 - val_accuracy: 0.4844 - val_loss: 0.9196\n",
      "Epoch 410/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7573 - loss: 0.4914 - val_accuracy: 0.4938 - val_loss: 0.9126\n",
      "Epoch 411/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7591 - loss: 0.4942 - val_accuracy: 0.4869 - val_loss: 0.9318\n",
      "Epoch 412/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7536 - loss: 0.4952 - val_accuracy: 0.4706 - val_loss: 0.9180\n",
      "Epoch 413/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7613 - loss: 0.4882 - val_accuracy: 0.4806 - val_loss: 0.9186\n",
      "Epoch 414/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7623 - loss: 0.4912 - val_accuracy: 0.4719 - val_loss: 0.9262\n",
      "Epoch 415/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7611 - loss: 0.4839 - val_accuracy: 0.4819 - val_loss: 0.9180\n",
      "Epoch 416/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7602 - loss: 0.4919 - val_accuracy: 0.4831 - val_loss: 0.9139\n",
      "Epoch 417/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7608 - loss: 0.4929 - val_accuracy: 0.4781 - val_loss: 0.9183\n",
      "Epoch 418/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7647 - loss: 0.4796 - val_accuracy: 0.4844 - val_loss: 0.9191\n",
      "Epoch 419/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7597 - loss: 0.4966 - val_accuracy: 0.4794 - val_loss: 0.9069\n",
      "Epoch 420/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7678 - loss: 0.4745 - val_accuracy: 0.4900 - val_loss: 0.9117\n",
      "Epoch 421/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7509 - loss: 0.5027 - val_accuracy: 0.4844 - val_loss: 0.9145\n",
      "Epoch 422/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7625 - loss: 0.4899 - val_accuracy: 0.4850 - val_loss: 0.9184\n",
      "Epoch 423/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7556 - loss: 0.4890 - val_accuracy: 0.4888 - val_loss: 0.9238\n",
      "Epoch 424/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7616 - loss: 0.4953 - val_accuracy: 0.4969 - val_loss: 0.9163\n",
      "Epoch 425/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7597 - loss: 0.4894 - val_accuracy: 0.4856 - val_loss: 0.9163\n",
      "Epoch 426/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7638 - loss: 0.4955 - val_accuracy: 0.4856 - val_loss: 0.9126\n",
      "Epoch 427/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7553 - loss: 0.4864 - val_accuracy: 0.4831 - val_loss: 0.9174\n",
      "Epoch 428/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7642 - loss: 0.4786 - val_accuracy: 0.4837 - val_loss: 0.9242\n",
      "Epoch 429/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7686 - loss: 0.4793 - val_accuracy: 0.4837 - val_loss: 0.9313\n",
      "Epoch 430/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7652 - loss: 0.4895 - val_accuracy: 0.4825 - val_loss: 0.9285\n",
      "Epoch 431/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7550 - loss: 0.4954 - val_accuracy: 0.4750 - val_loss: 0.9270\n",
      "Epoch 432/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7522 - loss: 0.4966 - val_accuracy: 0.4837 - val_loss: 0.9269\n",
      "Epoch 433/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7477 - loss: 0.5108 - val_accuracy: 0.4869 - val_loss: 0.9163\n",
      "Epoch 434/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7641 - loss: 0.4844 - val_accuracy: 0.4750 - val_loss: 0.9160\n",
      "Epoch 435/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7613 - loss: 0.4921 - val_accuracy: 0.4856 - val_loss: 0.9159\n",
      "Epoch 436/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7480 - loss: 0.4934 - val_accuracy: 0.4750 - val_loss: 0.9193\n",
      "Epoch 437/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7589 - loss: 0.4922 - val_accuracy: 0.4819 - val_loss: 0.9212\n",
      "Epoch 438/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7586 - loss: 0.4889 - val_accuracy: 0.4850 - val_loss: 0.9159\n",
      "Epoch 439/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7648 - loss: 0.4881 - val_accuracy: 0.4837 - val_loss: 0.9201\n",
      "Epoch 440/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7630 - loss: 0.4948 - val_accuracy: 0.4837 - val_loss: 0.9211\n",
      "Epoch 441/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7633 - loss: 0.4863 - val_accuracy: 0.4837 - val_loss: 0.9175\n",
      "Epoch 442/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7623 - loss: 0.4917 - val_accuracy: 0.4925 - val_loss: 0.9080\n",
      "Epoch 443/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7675 - loss: 0.4850 - val_accuracy: 0.4856 - val_loss: 0.9182\n",
      "Epoch 444/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7573 - loss: 0.4887 - val_accuracy: 0.4919 - val_loss: 0.9143\n",
      "Epoch 445/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7628 - loss: 0.4829 - val_accuracy: 0.4869 - val_loss: 0.9150\n",
      "Epoch 446/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7673 - loss: 0.4815 - val_accuracy: 0.4881 - val_loss: 0.9139\n",
      "Epoch 447/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7664 - loss: 0.4836 - val_accuracy: 0.4825 - val_loss: 0.9227\n",
      "Epoch 448/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7550 - loss: 0.4896 - val_accuracy: 0.4869 - val_loss: 0.9142\n",
      "Epoch 449/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7691 - loss: 0.4767 - val_accuracy: 0.4731 - val_loss: 0.9362\n",
      "Epoch 450/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7634 - loss: 0.4871 - val_accuracy: 0.4762 - val_loss: 0.9364\n",
      "Epoch 451/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7719 - loss: 0.4754 - val_accuracy: 0.4762 - val_loss: 0.9270\n",
      "Epoch 452/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7681 - loss: 0.4798 - val_accuracy: 0.4781 - val_loss: 0.9296\n",
      "Epoch 453/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7739 - loss: 0.4825 - val_accuracy: 0.4781 - val_loss: 0.9282\n",
      "Epoch 454/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7594 - loss: 0.4828 - val_accuracy: 0.4756 - val_loss: 0.9216\n",
      "Epoch 455/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7714 - loss: 0.4781 - val_accuracy: 0.4725 - val_loss: 0.9280\n",
      "Epoch 456/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7717 - loss: 0.4775 - val_accuracy: 0.4819 - val_loss: 0.9236\n",
      "Epoch 457/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7691 - loss: 0.4853 - val_accuracy: 0.4825 - val_loss: 0.9128\n",
      "Epoch 458/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7716 - loss: 0.4767 - val_accuracy: 0.4825 - val_loss: 0.9223\n",
      "Epoch 459/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7645 - loss: 0.4901 - val_accuracy: 0.4875 - val_loss: 0.9250\n",
      "Epoch 460/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7698 - loss: 0.4786 - val_accuracy: 0.4819 - val_loss: 0.9244\n",
      "Epoch 461/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7644 - loss: 0.4891 - val_accuracy: 0.4825 - val_loss: 0.9178\n",
      "Epoch 462/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7536 - loss: 0.4923 - val_accuracy: 0.4769 - val_loss: 0.9231\n",
      "Epoch 463/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7573 - loss: 0.4975 - val_accuracy: 0.4769 - val_loss: 0.9176\n",
      "Epoch 464/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7695 - loss: 0.4772 - val_accuracy: 0.4850 - val_loss: 0.9189\n",
      "Epoch 465/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7630 - loss: 0.4822 - val_accuracy: 0.4825 - val_loss: 0.9193\n",
      "Epoch 466/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7669 - loss: 0.4840 - val_accuracy: 0.4875 - val_loss: 0.9225\n",
      "Epoch 467/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7739 - loss: 0.4766 - val_accuracy: 0.4881 - val_loss: 0.9198\n",
      "Epoch 468/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7533 - loss: 0.4894 - val_accuracy: 0.4850 - val_loss: 0.9291\n",
      "Epoch 469/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7719 - loss: 0.4778 - val_accuracy: 0.4831 - val_loss: 0.9251\n",
      "Epoch 470/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7781 - loss: 0.4686 - val_accuracy: 0.4894 - val_loss: 0.9306\n",
      "Epoch 471/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7605 - loss: 0.4966 - val_accuracy: 0.4844 - val_loss: 0.9193\n",
      "Epoch 472/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7672 - loss: 0.4881 - val_accuracy: 0.4881 - val_loss: 0.9208\n",
      "Epoch 473/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7669 - loss: 0.4874 - val_accuracy: 0.4837 - val_loss: 0.9249\n",
      "Epoch 474/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7658 - loss: 0.4832 - val_accuracy: 0.4925 - val_loss: 0.9170\n",
      "Epoch 475/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7647 - loss: 0.4886 - val_accuracy: 0.4938 - val_loss: 0.9228\n",
      "Epoch 476/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7623 - loss: 0.4857 - val_accuracy: 0.4863 - val_loss: 0.9264\n",
      "Epoch 477/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7709 - loss: 0.4722 - val_accuracy: 0.4931 - val_loss: 0.9278\n",
      "Epoch 478/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7644 - loss: 0.4851 - val_accuracy: 0.4913 - val_loss: 0.9169\n",
      "Epoch 479/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7706 - loss: 0.4842 - val_accuracy: 0.4894 - val_loss: 0.9207\n",
      "Epoch 480/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7748 - loss: 0.4726 - val_accuracy: 0.4900 - val_loss: 0.9267\n",
      "Epoch 481/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7652 - loss: 0.4886 - val_accuracy: 0.4900 - val_loss: 0.9287\n",
      "Epoch 482/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7616 - loss: 0.4879 - val_accuracy: 0.4900 - val_loss: 0.9248\n",
      "Epoch 483/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7675 - loss: 0.4754 - val_accuracy: 0.4919 - val_loss: 0.9275\n",
      "Epoch 484/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7736 - loss: 0.4694 - val_accuracy: 0.4800 - val_loss: 0.9383\n",
      "Epoch 485/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7630 - loss: 0.4833 - val_accuracy: 0.4913 - val_loss: 0.9268\n",
      "Epoch 486/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7595 - loss: 0.4880 - val_accuracy: 0.4850 - val_loss: 0.9272\n",
      "Epoch 487/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7708 - loss: 0.4788 - val_accuracy: 0.4881 - val_loss: 0.9251\n",
      "Epoch 488/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.7664 - loss: 0.4819 - val_accuracy: 0.5050 - val_loss: 0.9218\n",
      "Epoch 489/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7688 - loss: 0.4812 - val_accuracy: 0.4881 - val_loss: 0.9353\n",
      "Epoch 490/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7792 - loss: 0.4673 - val_accuracy: 0.4900 - val_loss: 0.9328\n",
      "Epoch 491/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7748 - loss: 0.4693 - val_accuracy: 0.4831 - val_loss: 0.9308\n",
      "Epoch 492/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7677 - loss: 0.4756 - val_accuracy: 0.4888 - val_loss: 0.9277\n",
      "Epoch 493/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7644 - loss: 0.4856 - val_accuracy: 0.4981 - val_loss: 0.9308\n",
      "Epoch 494/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7727 - loss: 0.4783 - val_accuracy: 0.4988 - val_loss: 0.9240\n",
      "Epoch 495/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7692 - loss: 0.4784 - val_accuracy: 0.4875 - val_loss: 0.9343\n",
      "Epoch 496/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7633 - loss: 0.4789 - val_accuracy: 0.4825 - val_loss: 0.9313\n",
      "Epoch 497/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7695 - loss: 0.4809 - val_accuracy: 0.4806 - val_loss: 0.9341\n",
      "Epoch 498/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7650 - loss: 0.4851 - val_accuracy: 0.4856 - val_loss: 0.9265\n",
      "Epoch 499/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7680 - loss: 0.4753 - val_accuracy: 0.4856 - val_loss: 0.9270\n",
      "Epoch 500/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.4802 - val_accuracy: 0.4787 - val_loss: 0.9331\n",
      "Epoch 501/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7623 - loss: 0.4769 - val_accuracy: 0.4837 - val_loss: 0.9349\n",
      "Epoch 502/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7711 - loss: 0.4860 - val_accuracy: 0.4950 - val_loss: 0.9306\n",
      "Epoch 503/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7725 - loss: 0.4751 - val_accuracy: 0.4888 - val_loss: 0.9258\n",
      "Epoch 504/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.4832 - val_accuracy: 0.4888 - val_loss: 0.9262\n",
      "Epoch 505/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7548 - loss: 0.4934 - val_accuracy: 0.4875 - val_loss: 0.9221\n",
      "Epoch 506/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7663 - loss: 0.4821 - val_accuracy: 0.4875 - val_loss: 0.9338\n",
      "Epoch 507/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.4893 - val_accuracy: 0.4919 - val_loss: 0.9263\n",
      "Epoch 508/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7678 - loss: 0.4887 - val_accuracy: 0.4919 - val_loss: 0.9217\n",
      "Epoch 509/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7669 - loss: 0.4833 - val_accuracy: 0.4913 - val_loss: 0.9253\n",
      "Epoch 510/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7675 - loss: 0.4798 - val_accuracy: 0.4794 - val_loss: 0.9230\n",
      "Epoch 511/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.4786 - val_accuracy: 0.4844 - val_loss: 0.9217\n",
      "Epoch 512/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4724 - val_accuracy: 0.4925 - val_loss: 0.9288\n",
      "Epoch 513/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7638 - loss: 0.4785 - val_accuracy: 0.4913 - val_loss: 0.9263\n",
      "Epoch 514/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7722 - loss: 0.4726 - val_accuracy: 0.4875 - val_loss: 0.9249\n",
      "Epoch 515/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7669 - loss: 0.4799 - val_accuracy: 0.4963 - val_loss: 0.9267\n",
      "Epoch 516/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.4835 - val_accuracy: 0.4825 - val_loss: 0.9272\n",
      "Epoch 517/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7597 - loss: 0.4888 - val_accuracy: 0.4825 - val_loss: 0.9367\n",
      "Epoch 518/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7717 - loss: 0.4800 - val_accuracy: 0.4806 - val_loss: 0.9328\n",
      "Epoch 519/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.4805 - val_accuracy: 0.4819 - val_loss: 0.9256\n",
      "Epoch 520/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7717 - loss: 0.4773 - val_accuracy: 0.4831 - val_loss: 0.9388\n",
      "Epoch 521/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7670 - loss: 0.4805 - val_accuracy: 0.4988 - val_loss: 0.9336\n",
      "Epoch 522/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7597 - loss: 0.4823 - val_accuracy: 0.4875 - val_loss: 0.9280\n",
      "Epoch 523/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7677 - loss: 0.4794 - val_accuracy: 0.4825 - val_loss: 0.9276\n",
      "Epoch 524/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7667 - loss: 0.4863 - val_accuracy: 0.4913 - val_loss: 0.9236\n",
      "Epoch 525/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4794 - val_accuracy: 0.4931 - val_loss: 0.9346\n",
      "Epoch 526/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7736 - loss: 0.4738 - val_accuracy: 0.4875 - val_loss: 0.9303\n",
      "Epoch 527/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7595 - loss: 0.4922 - val_accuracy: 0.4894 - val_loss: 0.9367\n",
      "Epoch 528/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4682 - val_accuracy: 0.4913 - val_loss: 0.9365\n",
      "Epoch 529/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7681 - loss: 0.4798 - val_accuracy: 0.4875 - val_loss: 0.9324\n",
      "Epoch 530/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4729 - val_accuracy: 0.4850 - val_loss: 0.9289\n",
      "Epoch 531/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7664 - loss: 0.4774 - val_accuracy: 0.4888 - val_loss: 0.9380\n",
      "Epoch 532/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.4742 - val_accuracy: 0.4794 - val_loss: 0.9365\n",
      "Epoch 533/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7683 - loss: 0.4757 - val_accuracy: 0.4775 - val_loss: 0.9406\n",
      "Epoch 534/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7780 - loss: 0.4658 - val_accuracy: 0.4919 - val_loss: 0.9445\n",
      "Epoch 535/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7727 - loss: 0.4720 - val_accuracy: 0.4888 - val_loss: 0.9349\n",
      "Epoch 536/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.4780 - val_accuracy: 0.4900 - val_loss: 0.9344\n",
      "Epoch 537/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4721 - val_accuracy: 0.4819 - val_loss: 0.9409\n",
      "Epoch 538/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4717 - val_accuracy: 0.4794 - val_loss: 0.9426\n",
      "Epoch 539/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.4717 - val_accuracy: 0.4881 - val_loss: 0.9472\n",
      "Epoch 540/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7688 - loss: 0.4821 - val_accuracy: 0.4913 - val_loss: 0.9334\n",
      "Epoch 541/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4718 - val_accuracy: 0.4925 - val_loss: 0.9398\n",
      "Epoch 542/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7784 - loss: 0.4637 - val_accuracy: 0.4875 - val_loss: 0.9399\n",
      "Epoch 543/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.4777 - val_accuracy: 0.4969 - val_loss: 0.9387\n",
      "Epoch 544/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7705 - loss: 0.4731 - val_accuracy: 0.4913 - val_loss: 0.9460\n",
      "Epoch 545/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7745 - loss: 0.4744 - val_accuracy: 0.4919 - val_loss: 0.9444\n",
      "Epoch 546/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.4867 - val_accuracy: 0.4975 - val_loss: 0.9310\n",
      "Epoch 547/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7728 - loss: 0.4772 - val_accuracy: 0.4906 - val_loss: 0.9342\n",
      "Epoch 548/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.4641 - val_accuracy: 0.4925 - val_loss: 0.9298\n",
      "Epoch 549/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7778 - loss: 0.4649 - val_accuracy: 0.4938 - val_loss: 0.9333\n",
      "Epoch 550/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7700 - loss: 0.4822 - val_accuracy: 0.4869 - val_loss: 0.9384\n",
      "Epoch 551/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7736 - loss: 0.4737 - val_accuracy: 0.4837 - val_loss: 0.9372\n",
      "Epoch 552/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4710 - val_accuracy: 0.4913 - val_loss: 0.9387\n",
      "Epoch 553/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7698 - loss: 0.4736 - val_accuracy: 0.4969 - val_loss: 0.9285\n",
      "Epoch 554/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7681 - loss: 0.4710 - val_accuracy: 0.4894 - val_loss: 0.9326\n",
      "Epoch 555/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7705 - loss: 0.4811 - val_accuracy: 0.4850 - val_loss: 0.9381\n",
      "Epoch 556/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7820 - loss: 0.4666 - val_accuracy: 0.4894 - val_loss: 0.9381\n",
      "Epoch 557/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.4811 - val_accuracy: 0.4837 - val_loss: 0.9448\n",
      "Epoch 558/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7722 - loss: 0.4749 - val_accuracy: 0.4925 - val_loss: 0.9369\n",
      "Epoch 559/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4762 - val_accuracy: 0.4988 - val_loss: 0.9349\n",
      "Epoch 560/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7698 - loss: 0.4747 - val_accuracy: 0.5063 - val_loss: 0.9342\n",
      "Epoch 561/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7645 - loss: 0.4846 - val_accuracy: 0.5069 - val_loss: 0.9312\n",
      "Epoch 562/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7692 - loss: 0.4763 - val_accuracy: 0.4906 - val_loss: 0.9423\n",
      "Epoch 563/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.4772 - val_accuracy: 0.4906 - val_loss: 0.9418\n",
      "Epoch 564/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7738 - loss: 0.4715 - val_accuracy: 0.4938 - val_loss: 0.9302\n",
      "Epoch 565/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7636 - loss: 0.4756 - val_accuracy: 0.4781 - val_loss: 0.9313\n",
      "Epoch 566/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7641 - loss: 0.4786 - val_accuracy: 0.4938 - val_loss: 0.9358\n",
      "Epoch 567/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7759 - loss: 0.4675 - val_accuracy: 0.4981 - val_loss: 0.9295\n",
      "Epoch 568/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4671 - val_accuracy: 0.4906 - val_loss: 0.9319\n",
      "Epoch 569/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7714 - loss: 0.4707 - val_accuracy: 0.4806 - val_loss: 0.9393\n",
      "Epoch 570/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4664 - val_accuracy: 0.4888 - val_loss: 0.9344\n",
      "Epoch 571/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7786 - loss: 0.4616 - val_accuracy: 0.4844 - val_loss: 0.9410\n",
      "Epoch 572/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7789 - loss: 0.4663 - val_accuracy: 0.4863 - val_loss: 0.9486\n",
      "Epoch 573/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7630 - loss: 0.4800 - val_accuracy: 0.4969 - val_loss: 0.9387\n",
      "Epoch 574/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.4740 - val_accuracy: 0.4919 - val_loss: 0.9335\n",
      "Epoch 575/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7739 - loss: 0.4733 - val_accuracy: 0.4938 - val_loss: 0.9362\n",
      "Epoch 576/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.4706 - val_accuracy: 0.4844 - val_loss: 0.9389\n",
      "Epoch 577/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7625 - loss: 0.4844 - val_accuracy: 0.4888 - val_loss: 0.9383\n",
      "Epoch 578/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7814 - loss: 0.4568 - val_accuracy: 0.4938 - val_loss: 0.9402\n",
      "Epoch 579/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.4642 - val_accuracy: 0.5019 - val_loss: 0.9377\n",
      "Epoch 580/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7753 - loss: 0.4667 - val_accuracy: 0.5006 - val_loss: 0.9353\n",
      "Epoch 581/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7723 - loss: 0.4757 - val_accuracy: 0.4919 - val_loss: 0.9396\n",
      "Epoch 582/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.4717 - val_accuracy: 0.4956 - val_loss: 0.9414\n",
      "Epoch 583/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.4754 - val_accuracy: 0.4913 - val_loss: 0.9485\n",
      "Epoch 584/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.4715 - val_accuracy: 0.4856 - val_loss: 0.9422\n",
      "Epoch 585/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7697 - loss: 0.4759 - val_accuracy: 0.4981 - val_loss: 0.9424\n",
      "Epoch 586/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4576 - val_accuracy: 0.4994 - val_loss: 0.9470\n",
      "Epoch 587/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7698 - loss: 0.4733 - val_accuracy: 0.4850 - val_loss: 0.9479\n",
      "Epoch 588/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7708 - loss: 0.4706 - val_accuracy: 0.4831 - val_loss: 0.9482\n",
      "Epoch 589/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.4696 - val_accuracy: 0.4775 - val_loss: 0.9524\n",
      "Epoch 590/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7741 - loss: 0.4675 - val_accuracy: 0.4787 - val_loss: 0.9508\n",
      "Epoch 591/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7720 - loss: 0.4670 - val_accuracy: 0.4944 - val_loss: 0.9465\n",
      "Epoch 592/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7638 - loss: 0.4737 - val_accuracy: 0.4850 - val_loss: 0.9524\n",
      "Epoch 593/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7733 - loss: 0.4684 - val_accuracy: 0.4875 - val_loss: 0.9441\n",
      "Epoch 594/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7689 - loss: 0.4773 - val_accuracy: 0.4837 - val_loss: 0.9437\n",
      "Epoch 595/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7763 - loss: 0.4695 - val_accuracy: 0.4819 - val_loss: 0.9502\n",
      "Epoch 596/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7706 - loss: 0.4741 - val_accuracy: 0.4856 - val_loss: 0.9453\n",
      "Epoch 597/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7842 - loss: 0.4592 - val_accuracy: 0.4875 - val_loss: 0.9417\n",
      "Epoch 598/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.4769 - val_accuracy: 0.4894 - val_loss: 0.9476\n",
      "Epoch 599/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7881 - loss: 0.4620 - val_accuracy: 0.4913 - val_loss: 0.9436\n",
      "Epoch 600/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7713 - loss: 0.4750 - val_accuracy: 0.4863 - val_loss: 0.9518\n",
      "Epoch 601/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7722 - loss: 0.4766 - val_accuracy: 0.4844 - val_loss: 0.9374\n",
      "Epoch 602/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.4636 - val_accuracy: 0.4869 - val_loss: 0.9417\n",
      "Epoch 603/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.4621 - val_accuracy: 0.4875 - val_loss: 0.9488\n",
      "Epoch 604/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7805 - loss: 0.4606 - val_accuracy: 0.4881 - val_loss: 0.9561\n",
      "Epoch 605/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7822 - loss: 0.4612 - val_accuracy: 0.4831 - val_loss: 0.9599\n",
      "Epoch 606/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4556 - val_accuracy: 0.4975 - val_loss: 0.9599\n",
      "Epoch 607/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7733 - loss: 0.4677 - val_accuracy: 0.4881 - val_loss: 0.9575\n",
      "Epoch 608/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7719 - loss: 0.4673 - val_accuracy: 0.4894 - val_loss: 0.9506\n",
      "Epoch 609/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7809 - loss: 0.4578 - val_accuracy: 0.4938 - val_loss: 0.9516\n",
      "Epoch 610/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7752 - loss: 0.4634 - val_accuracy: 0.4956 - val_loss: 0.9512\n",
      "Epoch 611/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7748 - loss: 0.4652 - val_accuracy: 0.4913 - val_loss: 0.9522\n",
      "Epoch 612/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.4622 - val_accuracy: 0.4900 - val_loss: 0.9550\n",
      "Epoch 613/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4581 - val_accuracy: 0.4856 - val_loss: 0.9579\n",
      "Epoch 614/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7827 - loss: 0.4613 - val_accuracy: 0.4900 - val_loss: 0.9535\n",
      "Epoch 615/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7742 - loss: 0.4727 - val_accuracy: 0.4950 - val_loss: 0.9498\n",
      "Epoch 616/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7727 - loss: 0.4699 - val_accuracy: 0.4931 - val_loss: 0.9437\n",
      "Epoch 617/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7702 - loss: 0.4667 - val_accuracy: 0.4900 - val_loss: 0.9418\n",
      "Epoch 618/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7811 - loss: 0.4601 - val_accuracy: 0.4994 - val_loss: 0.9472\n",
      "Epoch 619/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7855 - loss: 0.4524 - val_accuracy: 0.4994 - val_loss: 0.9464\n",
      "Epoch 620/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.4622 - val_accuracy: 0.5013 - val_loss: 0.9416\n",
      "Epoch 621/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7803 - loss: 0.4636 - val_accuracy: 0.4863 - val_loss: 0.9514\n",
      "Epoch 622/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7689 - loss: 0.4853 - val_accuracy: 0.4919 - val_loss: 0.9457\n",
      "Epoch 623/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.4727 - val_accuracy: 0.4894 - val_loss: 0.9447\n",
      "Epoch 624/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7883 - loss: 0.4586 - val_accuracy: 0.5013 - val_loss: 0.9377\n",
      "Epoch 625/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7897 - loss: 0.4449 - val_accuracy: 0.4894 - val_loss: 0.9503\n",
      "Epoch 626/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 0.4634 - val_accuracy: 0.4913 - val_loss: 0.9441\n",
      "Epoch 627/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7730 - loss: 0.4790 - val_accuracy: 0.4881 - val_loss: 0.9471\n",
      "Epoch 628/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.4711 - val_accuracy: 0.4913 - val_loss: 0.9424\n",
      "Epoch 629/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.4738 - val_accuracy: 0.4850 - val_loss: 0.9453\n",
      "Epoch 630/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7764 - loss: 0.4711 - val_accuracy: 0.4894 - val_loss: 0.9462\n",
      "Epoch 631/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7723 - loss: 0.4736 - val_accuracy: 0.4938 - val_loss: 0.9389\n",
      "Epoch 632/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7748 - loss: 0.4697 - val_accuracy: 0.4938 - val_loss: 0.9422\n",
      "Epoch 633/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7694 - loss: 0.4765 - val_accuracy: 0.4931 - val_loss: 0.9378\n",
      "Epoch 634/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7763 - loss: 0.4661 - val_accuracy: 0.4969 - val_loss: 0.9391\n",
      "Epoch 635/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7742 - loss: 0.4675 - val_accuracy: 0.4869 - val_loss: 0.9411\n",
      "Epoch 636/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7873 - loss: 0.4513 - val_accuracy: 0.4931 - val_loss: 0.9432\n",
      "Epoch 637/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7770 - loss: 0.4702 - val_accuracy: 0.4856 - val_loss: 0.9523\n",
      "Epoch 638/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7808 - loss: 0.4600 - val_accuracy: 0.4938 - val_loss: 0.9456\n",
      "Epoch 639/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7700 - loss: 0.4723 - val_accuracy: 0.4900 - val_loss: 0.9494\n",
      "Epoch 640/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7759 - loss: 0.4679 - val_accuracy: 0.4969 - val_loss: 0.9438\n",
      "Epoch 641/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7856 - loss: 0.4596 - val_accuracy: 0.4963 - val_loss: 0.9357\n",
      "Epoch 642/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7819 - loss: 0.4604 - val_accuracy: 0.5013 - val_loss: 0.9319\n",
      "Epoch 643/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7739 - loss: 0.4702 - val_accuracy: 0.5094 - val_loss: 0.9405\n",
      "Epoch 644/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7748 - loss: 0.4669 - val_accuracy: 0.4994 - val_loss: 0.9410\n",
      "Epoch 645/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.4544 - val_accuracy: 0.5025 - val_loss: 0.9486\n",
      "Epoch 646/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7837 - loss: 0.4625 - val_accuracy: 0.4969 - val_loss: 0.9537\n",
      "Epoch 647/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7791 - loss: 0.4623 - val_accuracy: 0.5100 - val_loss: 0.9386\n",
      "Epoch 648/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7772 - loss: 0.4605 - val_accuracy: 0.5013 - val_loss: 0.9540\n",
      "Epoch 649/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7777 - loss: 0.4643 - val_accuracy: 0.4938 - val_loss: 0.9568\n",
      "Epoch 650/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.4562 - val_accuracy: 0.4938 - val_loss: 0.9528\n",
      "Epoch 651/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7731 - loss: 0.4668 - val_accuracy: 0.4894 - val_loss: 0.9565\n",
      "Epoch 652/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.4659 - val_accuracy: 0.4850 - val_loss: 0.9518\n",
      "Epoch 653/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7797 - loss: 0.4655 - val_accuracy: 0.4837 - val_loss: 0.9556\n",
      "Epoch 654/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7705 - loss: 0.4651 - val_accuracy: 0.4925 - val_loss: 0.9561\n",
      "Epoch 655/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7823 - loss: 0.4630 - val_accuracy: 0.4944 - val_loss: 0.9535\n",
      "Epoch 656/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.4755 - val_accuracy: 0.5025 - val_loss: 0.9543\n",
      "Epoch 657/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7859 - loss: 0.4534 - val_accuracy: 0.4869 - val_loss: 0.9624\n",
      "Epoch 658/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7750 - loss: 0.4615 - val_accuracy: 0.4944 - val_loss: 0.9604\n",
      "Epoch 659/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7925 - loss: 0.4494 - val_accuracy: 0.4869 - val_loss: 0.9589\n",
      "Epoch 660/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7781 - loss: 0.4697 - val_accuracy: 0.4869 - val_loss: 0.9573\n",
      "Epoch 661/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 0.4685 - val_accuracy: 0.4944 - val_loss: 0.9561\n",
      "Epoch 662/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7887 - loss: 0.4581 - val_accuracy: 0.4850 - val_loss: 0.9649\n",
      "Epoch 663/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.4708 - val_accuracy: 0.4906 - val_loss: 0.9609\n",
      "Epoch 664/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7797 - loss: 0.4600 - val_accuracy: 0.4975 - val_loss: 0.9565\n",
      "Epoch 665/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7852 - loss: 0.4580 - val_accuracy: 0.4944 - val_loss: 0.9674\n",
      "Epoch 666/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7731 - loss: 0.4687 - val_accuracy: 0.4975 - val_loss: 0.9624\n",
      "Epoch 667/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7714 - loss: 0.4670 - val_accuracy: 0.4994 - val_loss: 0.9578\n",
      "Epoch 668/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7680 - loss: 0.4766 - val_accuracy: 0.4975 - val_loss: 0.9454\n",
      "Epoch 669/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7716 - loss: 0.4705 - val_accuracy: 0.4988 - val_loss: 0.9520\n",
      "Epoch 670/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7845 - loss: 0.4582 - val_accuracy: 0.4888 - val_loss: 0.9634\n",
      "Epoch 671/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7823 - loss: 0.4606 - val_accuracy: 0.4881 - val_loss: 0.9581\n",
      "Epoch 672/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7731 - loss: 0.4694 - val_accuracy: 0.4831 - val_loss: 0.9685\n",
      "Epoch 673/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.4570 - val_accuracy: 0.4913 - val_loss: 0.9676\n",
      "Epoch 674/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7834 - loss: 0.4570 - val_accuracy: 0.4825 - val_loss: 0.9674\n",
      "Epoch 675/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4636 - val_accuracy: 0.4875 - val_loss: 0.9613\n",
      "Epoch 676/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.4603 - val_accuracy: 0.4963 - val_loss: 0.9560\n",
      "Epoch 677/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7764 - loss: 0.4612 - val_accuracy: 0.4856 - val_loss: 0.9666\n",
      "Epoch 678/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7722 - loss: 0.4702 - val_accuracy: 0.4881 - val_loss: 0.9674\n",
      "Epoch 679/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7806 - loss: 0.4609 - val_accuracy: 0.4875 - val_loss: 0.9664\n",
      "Epoch 680/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7714 - loss: 0.4665 - val_accuracy: 0.4856 - val_loss: 0.9550\n",
      "Epoch 681/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7797 - loss: 0.4602 - val_accuracy: 0.4894 - val_loss: 0.9686\n",
      "Epoch 682/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7716 - loss: 0.4752 - val_accuracy: 0.4825 - val_loss: 0.9625\n",
      "Epoch 683/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.4663 - val_accuracy: 0.4931 - val_loss: 0.9499\n",
      "Epoch 684/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7806 - loss: 0.4554 - val_accuracy: 0.4963 - val_loss: 0.9490\n",
      "Epoch 685/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7862 - loss: 0.4549 - val_accuracy: 0.4944 - val_loss: 0.9584\n",
      "Epoch 686/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7767 - loss: 0.4612 - val_accuracy: 0.4888 - val_loss: 0.9684\n",
      "Epoch 687/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7783 - loss: 0.4634 - val_accuracy: 0.4944 - val_loss: 0.9550\n",
      "Epoch 688/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7711 - loss: 0.4687 - val_accuracy: 0.4875 - val_loss: 0.9547\n",
      "Epoch 689/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.4512 - val_accuracy: 0.4894 - val_loss: 0.9527\n",
      "Epoch 690/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7788 - loss: 0.4573 - val_accuracy: 0.4919 - val_loss: 0.9613\n",
      "Epoch 691/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7862 - loss: 0.4560 - val_accuracy: 0.4944 - val_loss: 0.9638\n",
      "Epoch 692/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7809 - loss: 0.4562 - val_accuracy: 0.4762 - val_loss: 0.9592\n",
      "Epoch 693/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.4609 - val_accuracy: 0.4844 - val_loss: 0.9612\n",
      "Epoch 694/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7909 - loss: 0.4493 - val_accuracy: 0.4894 - val_loss: 0.9674\n",
      "Epoch 695/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7758 - loss: 0.4597 - val_accuracy: 0.5000 - val_loss: 0.9657\n",
      "Epoch 696/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7773 - loss: 0.4631 - val_accuracy: 0.4831 - val_loss: 0.9667\n",
      "Epoch 697/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7850 - loss: 0.4526 - val_accuracy: 0.4900 - val_loss: 0.9562\n",
      "Epoch 698/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7752 - loss: 0.4659 - val_accuracy: 0.4919 - val_loss: 0.9636\n",
      "Epoch 699/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.4699 - val_accuracy: 0.4837 - val_loss: 0.9643\n",
      "Epoch 700/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.4583 - val_accuracy: 0.4869 - val_loss: 0.9668\n",
      "Epoch 701/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7755 - loss: 0.4670 - val_accuracy: 0.4938 - val_loss: 0.9676\n",
      "Epoch 702/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7703 - loss: 0.4696 - val_accuracy: 0.4931 - val_loss: 0.9567\n",
      "Epoch 703/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.4610 - val_accuracy: 0.4819 - val_loss: 0.9595\n",
      "Epoch 704/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7748 - loss: 0.4625 - val_accuracy: 0.4869 - val_loss: 0.9667\n",
      "Epoch 705/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7819 - loss: 0.4616 - val_accuracy: 0.4888 - val_loss: 0.9574\n",
      "Epoch 706/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7822 - loss: 0.4618 - val_accuracy: 0.4869 - val_loss: 0.9618\n",
      "Epoch 707/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7833 - loss: 0.4638 - val_accuracy: 0.4800 - val_loss: 0.9642\n",
      "Epoch 708/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.4558 - val_accuracy: 0.4812 - val_loss: 0.9663\n",
      "Epoch 709/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7775 - loss: 0.4576 - val_accuracy: 0.4825 - val_loss: 0.9623\n",
      "Epoch 710/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7839 - loss: 0.4570 - val_accuracy: 0.4837 - val_loss: 0.9654\n",
      "Epoch 711/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7753 - loss: 0.4653 - val_accuracy: 0.4819 - val_loss: 0.9527\n",
      "Epoch 712/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7738 - loss: 0.4630 - val_accuracy: 0.4938 - val_loss: 0.9504\n",
      "Epoch 713/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.4518 - val_accuracy: 0.4900 - val_loss: 0.9666\n",
      "Epoch 714/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.4686 - val_accuracy: 0.4931 - val_loss: 0.9679\n",
      "Epoch 715/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 0.4630 - val_accuracy: 0.4869 - val_loss: 0.9758\n",
      "Epoch 716/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.4649 - val_accuracy: 0.4863 - val_loss: 0.9616\n",
      "Epoch 717/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7744 - loss: 0.4575 - val_accuracy: 0.4931 - val_loss: 0.9626\n",
      "Epoch 718/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.4537 - val_accuracy: 0.4812 - val_loss: 0.9693\n",
      "Epoch 719/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.4525 - val_accuracy: 0.4844 - val_loss: 0.9743\n",
      "Epoch 720/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7900 - loss: 0.4511 - val_accuracy: 0.4856 - val_loss: 0.9763\n",
      "Epoch 721/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7772 - loss: 0.4604 - val_accuracy: 0.4875 - val_loss: 0.9746\n",
      "Epoch 722/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7856 - loss: 0.4558 - val_accuracy: 0.4888 - val_loss: 0.9718\n",
      "Epoch 723/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7880 - loss: 0.4548 - val_accuracy: 0.4881 - val_loss: 0.9683\n",
      "Epoch 724/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7898 - loss: 0.4455 - val_accuracy: 0.4931 - val_loss: 0.9684\n",
      "Epoch 725/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7819 - loss: 0.4609 - val_accuracy: 0.5000 - val_loss: 0.9628\n",
      "Epoch 726/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7816 - loss: 0.4581 - val_accuracy: 0.4956 - val_loss: 0.9790\n",
      "Epoch 727/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7794 - loss: 0.4571 - val_accuracy: 0.5094 - val_loss: 0.9647\n",
      "Epoch 728/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7856 - loss: 0.4552 - val_accuracy: 0.4950 - val_loss: 0.9671\n",
      "Epoch 729/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7766 - loss: 0.4582 - val_accuracy: 0.4988 - val_loss: 0.9635\n",
      "Epoch 730/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7877 - loss: 0.4547 - val_accuracy: 0.5006 - val_loss: 0.9670\n",
      "Epoch 731/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7858 - loss: 0.4484 - val_accuracy: 0.4919 - val_loss: 0.9678\n",
      "Epoch 732/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.4572 - val_accuracy: 0.4963 - val_loss: 0.9627\n",
      "Epoch 733/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7770 - loss: 0.4661 - val_accuracy: 0.4981 - val_loss: 0.9614\n",
      "Epoch 734/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7791 - loss: 0.4596 - val_accuracy: 0.5038 - val_loss: 0.9566\n",
      "Epoch 735/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7817 - loss: 0.4509 - val_accuracy: 0.4931 - val_loss: 0.9678\n",
      "Epoch 736/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.4612 - val_accuracy: 0.4988 - val_loss: 0.9577\n",
      "Epoch 737/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7830 - loss: 0.4616 - val_accuracy: 0.5019 - val_loss: 0.9564\n",
      "Epoch 738/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7848 - loss: 0.4567 - val_accuracy: 0.4963 - val_loss: 0.9660\n",
      "Epoch 739/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.4618 - val_accuracy: 0.4931 - val_loss: 0.9607\n",
      "Epoch 740/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7869 - loss: 0.4462 - val_accuracy: 0.4981 - val_loss: 0.9669\n",
      "Epoch 741/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7834 - loss: 0.4528 - val_accuracy: 0.4919 - val_loss: 0.9710\n",
      "Epoch 742/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7837 - loss: 0.4585 - val_accuracy: 0.5044 - val_loss: 0.9678\n",
      "Epoch 743/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7811 - loss: 0.4577 - val_accuracy: 0.5006 - val_loss: 0.9641\n",
      "Epoch 744/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7744 - loss: 0.4720 - val_accuracy: 0.4994 - val_loss: 0.9575\n",
      "Epoch 745/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7752 - loss: 0.4651 - val_accuracy: 0.4975 - val_loss: 0.9553\n",
      "Epoch 746/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.4586 - val_accuracy: 0.5088 - val_loss: 0.9568\n",
      "Epoch 747/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7739 - loss: 0.4671 - val_accuracy: 0.5044 - val_loss: 0.9705\n",
      "Epoch 748/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7773 - loss: 0.4659 - val_accuracy: 0.4981 - val_loss: 0.9608\n",
      "Epoch 749/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.4518 - val_accuracy: 0.4969 - val_loss: 0.9690\n",
      "Epoch 750/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7812 - loss: 0.4639 - val_accuracy: 0.4906 - val_loss: 0.9646\n",
      "Epoch 751/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7795 - loss: 0.4535 - val_accuracy: 0.4938 - val_loss: 0.9654\n",
      "Epoch 752/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7830 - loss: 0.4533 - val_accuracy: 0.5000 - val_loss: 0.9611\n",
      "Epoch 753/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7856 - loss: 0.4513 - val_accuracy: 0.5000 - val_loss: 0.9613\n",
      "Epoch 754/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.4591 - val_accuracy: 0.4969 - val_loss: 0.9548\n",
      "Epoch 755/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7778 - loss: 0.4559 - val_accuracy: 0.4981 - val_loss: 0.9587\n",
      "Epoch 756/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7758 - loss: 0.4633 - val_accuracy: 0.4913 - val_loss: 0.9603\n",
      "Epoch 757/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7777 - loss: 0.4556 - val_accuracy: 0.4931 - val_loss: 0.9533\n",
      "Epoch 758/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7811 - loss: 0.4591 - val_accuracy: 0.4963 - val_loss: 0.9613\n",
      "Epoch 759/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7884 - loss: 0.4554 - val_accuracy: 0.5013 - val_loss: 0.9600\n",
      "Epoch 760/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7848 - loss: 0.4577 - val_accuracy: 0.4994 - val_loss: 0.9599\n",
      "Epoch 761/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7756 - loss: 0.4671 - val_accuracy: 0.4856 - val_loss: 0.9619\n",
      "Epoch 762/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7862 - loss: 0.4552 - val_accuracy: 0.4906 - val_loss: 0.9626\n",
      "Epoch 763/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7803 - loss: 0.4606 - val_accuracy: 0.4969 - val_loss: 0.9619\n",
      "Epoch 764/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7836 - loss: 0.4533 - val_accuracy: 0.5006 - val_loss: 0.9707\n",
      "Epoch 765/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7856 - loss: 0.4543 - val_accuracy: 0.4988 - val_loss: 0.9661\n",
      "Epoch 766/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.4507 - val_accuracy: 0.4950 - val_loss: 0.9636\n",
      "Epoch 767/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7905 - loss: 0.4512 - val_accuracy: 0.4938 - val_loss: 0.9626\n",
      "Epoch 768/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7798 - loss: 0.4530 - val_accuracy: 0.4906 - val_loss: 0.9694\n",
      "Epoch 769/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7817 - loss: 0.4520 - val_accuracy: 0.4850 - val_loss: 0.9648\n",
      "Epoch 770/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7836 - loss: 0.4515 - val_accuracy: 0.5031 - val_loss: 0.9558\n",
      "Epoch 771/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7850 - loss: 0.4525 - val_accuracy: 0.4900 - val_loss: 0.9558\n",
      "Epoch 772/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7911 - loss: 0.4374 - val_accuracy: 0.4863 - val_loss: 0.9628\n",
      "Epoch 773/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.4526 - val_accuracy: 0.5031 - val_loss: 0.9622\n",
      "Epoch 774/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7792 - loss: 0.4612 - val_accuracy: 0.5050 - val_loss: 0.9629\n",
      "Epoch 775/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7805 - loss: 0.4614 - val_accuracy: 0.4875 - val_loss: 0.9682\n",
      "Epoch 776/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7895 - loss: 0.4501 - val_accuracy: 0.4925 - val_loss: 0.9733\n",
      "Epoch 777/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7830 - loss: 0.4540 - val_accuracy: 0.5088 - val_loss: 0.9608\n",
      "Epoch 778/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7864 - loss: 0.4488 - val_accuracy: 0.4944 - val_loss: 0.9718\n",
      "Epoch 779/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4480 - val_accuracy: 0.5000 - val_loss: 0.9708\n",
      "Epoch 780/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7806 - loss: 0.4544 - val_accuracy: 0.4969 - val_loss: 0.9620\n",
      "Epoch 781/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7848 - loss: 0.4546 - val_accuracy: 0.4975 - val_loss: 0.9683\n",
      "Epoch 782/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7833 - loss: 0.4621 - val_accuracy: 0.4969 - val_loss: 0.9747\n",
      "Epoch 783/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7831 - loss: 0.4499 - val_accuracy: 0.5131 - val_loss: 0.9695\n",
      "Epoch 784/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7831 - loss: 0.4528 - val_accuracy: 0.5044 - val_loss: 0.9653\n",
      "Epoch 785/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7809 - loss: 0.4508 - val_accuracy: 0.4938 - val_loss: 0.9695\n",
      "Epoch 786/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7878 - loss: 0.4485 - val_accuracy: 0.5006 - val_loss: 0.9664\n",
      "Epoch 787/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7847 - loss: 0.4529 - val_accuracy: 0.4919 - val_loss: 0.9719\n",
      "Epoch 788/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.4614 - val_accuracy: 0.4863 - val_loss: 0.9777\n",
      "Epoch 789/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7802 - loss: 0.4630 - val_accuracy: 0.4988 - val_loss: 0.9698\n",
      "Epoch 790/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7830 - loss: 0.4517 - val_accuracy: 0.5063 - val_loss: 0.9704\n",
      "Epoch 791/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7898 - loss: 0.4538 - val_accuracy: 0.4906 - val_loss: 0.9650\n",
      "Epoch 792/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7845 - loss: 0.4589 - val_accuracy: 0.5000 - val_loss: 0.9574\n",
      "Epoch 793/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7902 - loss: 0.4532 - val_accuracy: 0.5169 - val_loss: 0.9560\n",
      "Epoch 794/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7886 - loss: 0.4552 - val_accuracy: 0.5081 - val_loss: 0.9576\n",
      "Epoch 795/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7880 - loss: 0.4540 - val_accuracy: 0.5156 - val_loss: 0.9656\n",
      "Epoch 796/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7867 - loss: 0.4505 - val_accuracy: 0.4994 - val_loss: 0.9650\n",
      "Epoch 797/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7916 - loss: 0.4576 - val_accuracy: 0.4931 - val_loss: 0.9751\n",
      "Epoch 798/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7761 - loss: 0.4689 - val_accuracy: 0.4975 - val_loss: 0.9663\n",
      "Epoch 799/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7759 - loss: 0.4567 - val_accuracy: 0.5025 - val_loss: 0.9608\n",
      "Epoch 800/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7866 - loss: 0.4522 - val_accuracy: 0.4938 - val_loss: 0.9656\n",
      "Epoch 801/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7841 - loss: 0.4514 - val_accuracy: 0.5031 - val_loss: 0.9638\n",
      "Epoch 802/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7950 - loss: 0.4457 - val_accuracy: 0.4900 - val_loss: 0.9700\n",
      "Epoch 803/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.4594 - val_accuracy: 0.4975 - val_loss: 0.9702\n",
      "Epoch 804/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7858 - loss: 0.4555 - val_accuracy: 0.4837 - val_loss: 0.9687\n",
      "Epoch 805/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7866 - loss: 0.4527 - val_accuracy: 0.4931 - val_loss: 0.9734\n",
      "Epoch 806/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7906 - loss: 0.4535 - val_accuracy: 0.4919 - val_loss: 0.9782\n",
      "Epoch 807/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7883 - loss: 0.4540 - val_accuracy: 0.4969 - val_loss: 0.9795\n",
      "Epoch 808/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7847 - loss: 0.4556 - val_accuracy: 0.4975 - val_loss: 0.9683\n",
      "Epoch 809/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7855 - loss: 0.4512 - val_accuracy: 0.4988 - val_loss: 0.9712\n",
      "Epoch 810/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8019 - loss: 0.4297 - val_accuracy: 0.4913 - val_loss: 0.9686\n",
      "Epoch 811/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7822 - loss: 0.4583 - val_accuracy: 0.4894 - val_loss: 0.9621\n",
      "Epoch 812/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7825 - loss: 0.4519 - val_accuracy: 0.4900 - val_loss: 0.9775\n",
      "Epoch 813/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7845 - loss: 0.4534 - val_accuracy: 0.4981 - val_loss: 0.9634\n",
      "Epoch 814/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7833 - loss: 0.4531 - val_accuracy: 0.4969 - val_loss: 0.9767\n",
      "Epoch 815/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7906 - loss: 0.4486 - val_accuracy: 0.4938 - val_loss: 0.9759\n",
      "Epoch 816/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7898 - loss: 0.4452 - val_accuracy: 0.4925 - val_loss: 0.9790\n",
      "Epoch 817/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7812 - loss: 0.4607 - val_accuracy: 0.4956 - val_loss: 0.9748\n",
      "Epoch 818/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7789 - loss: 0.4542 - val_accuracy: 0.4931 - val_loss: 0.9793\n",
      "Epoch 819/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7788 - loss: 0.4588 - val_accuracy: 0.4837 - val_loss: 0.9729\n",
      "Epoch 820/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7820 - loss: 0.4542 - val_accuracy: 0.5013 - val_loss: 0.9661\n",
      "Epoch 821/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7845 - loss: 0.4572 - val_accuracy: 0.5081 - val_loss: 0.9667\n",
      "Epoch 822/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7895 - loss: 0.4469 - val_accuracy: 0.4919 - val_loss: 0.9690\n",
      "Epoch 823/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7861 - loss: 0.4454 - val_accuracy: 0.5025 - val_loss: 0.9537\n",
      "Epoch 824/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7925 - loss: 0.4459 - val_accuracy: 0.4881 - val_loss: 0.9730\n",
      "Epoch 825/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7820 - loss: 0.4522 - val_accuracy: 0.4875 - val_loss: 0.9813\n",
      "Epoch 826/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7877 - loss: 0.4433 - val_accuracy: 0.4888 - val_loss: 0.9778\n",
      "Epoch 827/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7820 - loss: 0.4563 - val_accuracy: 0.5006 - val_loss: 0.9760\n",
      "Epoch 828/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7853 - loss: 0.4532 - val_accuracy: 0.4863 - val_loss: 0.9718\n",
      "Epoch 829/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7892 - loss: 0.4469 - val_accuracy: 0.4894 - val_loss: 0.9768\n",
      "Epoch 830/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7847 - loss: 0.4571 - val_accuracy: 0.4850 - val_loss: 0.9796\n",
      "Epoch 831/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7897 - loss: 0.4447 - val_accuracy: 0.4888 - val_loss: 0.9756\n",
      "Epoch 832/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7852 - loss: 0.4512 - val_accuracy: 0.4844 - val_loss: 0.9743\n",
      "Epoch 833/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7834 - loss: 0.4536 - val_accuracy: 0.4913 - val_loss: 0.9757\n",
      "Epoch 834/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7770 - loss: 0.4651 - val_accuracy: 0.4931 - val_loss: 0.9723\n",
      "Epoch 835/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7850 - loss: 0.4497 - val_accuracy: 0.4894 - val_loss: 0.9772\n",
      "Epoch 836/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7864 - loss: 0.4524 - val_accuracy: 0.5031 - val_loss: 0.9774\n",
      "Epoch 837/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7844 - loss: 0.4528 - val_accuracy: 0.4969 - val_loss: 0.9741\n",
      "Epoch 838/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7842 - loss: 0.4567 - val_accuracy: 0.5006 - val_loss: 0.9692\n",
      "Epoch 839/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7861 - loss: 0.4567 - val_accuracy: 0.4963 - val_loss: 0.9665\n",
      "Epoch 840/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7900 - loss: 0.4454 - val_accuracy: 0.4956 - val_loss: 0.9708\n",
      "Epoch 841/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7956 - loss: 0.4413 - val_accuracy: 0.4931 - val_loss: 0.9803\n",
      "Epoch 842/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7939 - loss: 0.4425 - val_accuracy: 0.4900 - val_loss: 0.9777\n",
      "Epoch 843/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7914 - loss: 0.4404 - val_accuracy: 0.4931 - val_loss: 0.9877\n",
      "Epoch 844/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7833 - loss: 0.4469 - val_accuracy: 0.4994 - val_loss: 0.9783\n",
      "Epoch 845/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7816 - loss: 0.4516 - val_accuracy: 0.4956 - val_loss: 0.9696\n",
      "Epoch 846/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7866 - loss: 0.4476 - val_accuracy: 0.4969 - val_loss: 0.9755\n",
      "Epoch 847/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.7823 - loss: 0.4528 - val_accuracy: 0.4938 - val_loss: 0.9702\n",
      "Epoch 848/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7944 - loss: 0.4417 - val_accuracy: 0.5050 - val_loss: 0.9748\n",
      "Epoch 849/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7820 - loss: 0.4570 - val_accuracy: 0.5044 - val_loss: 0.9781\n",
      "Epoch 850/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.7850 - loss: 0.4597 - val_accuracy: 0.4969 - val_loss: 0.9810\n",
      "Epoch 851/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7850 - loss: 0.4548 - val_accuracy: 0.5031 - val_loss: 0.9802\n",
      "Epoch 852/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7869 - loss: 0.4566 - val_accuracy: 0.5056 - val_loss: 0.9739\n",
      "Epoch 853/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7770 - loss: 0.4589 - val_accuracy: 0.5113 - val_loss: 0.9744\n",
      "Epoch 854/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.7803 - loss: 0.4555 - val_accuracy: 0.5119 - val_loss: 0.9722\n",
      "Epoch 855/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7916 - loss: 0.4491 - val_accuracy: 0.5075 - val_loss: 0.9769\n",
      "Epoch 856/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7925 - loss: 0.4423 - val_accuracy: 0.5119 - val_loss: 0.9687\n",
      "Epoch 857/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7886 - loss: 0.4405 - val_accuracy: 0.5081 - val_loss: 0.9714\n",
      "Epoch 858/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7875 - loss: 0.4453 - val_accuracy: 0.5031 - val_loss: 0.9834\n",
      "Epoch 859/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.7898 - loss: 0.4447 - val_accuracy: 0.5056 - val_loss: 0.9719\n",
      "Epoch 860/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7894 - loss: 0.4431 - val_accuracy: 0.5044 - val_loss: 0.9704\n",
      "Epoch 861/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7814 - loss: 0.4530 - val_accuracy: 0.5013 - val_loss: 0.9780\n",
      "Epoch 862/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7864 - loss: 0.4493 - val_accuracy: 0.4981 - val_loss: 0.9761\n",
      "Epoch 863/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7898 - loss: 0.4510 - val_accuracy: 0.4906 - val_loss: 0.9730\n",
      "Epoch 864/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7881 - loss: 0.4509 - val_accuracy: 0.4925 - val_loss: 0.9771\n",
      "Epoch 865/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7898 - loss: 0.4488 - val_accuracy: 0.5000 - val_loss: 0.9698\n",
      "Epoch 866/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.7828 - loss: 0.4551 - val_accuracy: 0.4925 - val_loss: 0.9778\n",
      "Epoch 867/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7875 - loss: 0.4496 - val_accuracy: 0.4994 - val_loss: 0.9809\n",
      "Epoch 868/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7852 - loss: 0.4462 - val_accuracy: 0.5044 - val_loss: 0.9790\n",
      "Epoch 869/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7919 - loss: 0.4493 - val_accuracy: 0.4931 - val_loss: 0.9856\n",
      "Epoch 870/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7873 - loss: 0.4574 - val_accuracy: 0.4963 - val_loss: 0.9717\n",
      "Epoch 871/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7900 - loss: 0.4486 - val_accuracy: 0.4956 - val_loss: 0.9732\n",
      "Epoch 872/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.7886 - loss: 0.4497 - val_accuracy: 0.4938 - val_loss: 0.9820\n",
      "Epoch 873/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7853 - loss: 0.4498 - val_accuracy: 0.5006 - val_loss: 0.9802\n",
      "Epoch 874/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7830 - loss: 0.4571 - val_accuracy: 0.5031 - val_loss: 0.9769\n",
      "Epoch 875/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.7883 - loss: 0.4474 - val_accuracy: 0.5013 - val_loss: 0.9775\n",
      "Epoch 876/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.7878 - loss: 0.4484 - val_accuracy: 0.4919 - val_loss: 0.9785\n",
      "Epoch 877/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7864 - loss: 0.4504 - val_accuracy: 0.4969 - val_loss: 0.9750\n",
      "Epoch 878/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7895 - loss: 0.4411 - val_accuracy: 0.5038 - val_loss: 0.9759\n",
      "Epoch 879/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7853 - loss: 0.4465 - val_accuracy: 0.5019 - val_loss: 0.9748\n",
      "Epoch 880/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7887 - loss: 0.4469 - val_accuracy: 0.4881 - val_loss: 0.9789\n",
      "Epoch 881/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7858 - loss: 0.4525 - val_accuracy: 0.4956 - val_loss: 0.9814\n",
      "Epoch 882/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7883 - loss: 0.4428 - val_accuracy: 0.4981 - val_loss: 0.9805\n",
      "Epoch 883/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7891 - loss: 0.4409 - val_accuracy: 0.4900 - val_loss: 0.9837\n",
      "Epoch 884/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7922 - loss: 0.4425 - val_accuracy: 0.5013 - val_loss: 0.9826\n",
      "Epoch 885/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7948 - loss: 0.4397 - val_accuracy: 0.4988 - val_loss: 0.9932\n",
      "Epoch 886/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7842 - loss: 0.4528 - val_accuracy: 0.4881 - val_loss: 0.9929\n",
      "Epoch 887/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7680 - loss: 0.4652 - val_accuracy: 0.4925 - val_loss: 0.9854\n",
      "Epoch 888/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7895 - loss: 0.4371 - val_accuracy: 0.4988 - val_loss: 0.9843\n",
      "Epoch 889/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7873 - loss: 0.4493 - val_accuracy: 0.4944 - val_loss: 0.9819\n",
      "Epoch 890/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7917 - loss: 0.4404 - val_accuracy: 0.4919 - val_loss: 0.9766\n",
      "Epoch 891/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7945 - loss: 0.4403 - val_accuracy: 0.4981 - val_loss: 0.9878\n",
      "Epoch 892/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7844 - loss: 0.4575 - val_accuracy: 0.5019 - val_loss: 0.9755\n",
      "Epoch 893/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7914 - loss: 0.4546 - val_accuracy: 0.4981 - val_loss: 0.9663\n",
      "Epoch 894/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7889 - loss: 0.4483 - val_accuracy: 0.5031 - val_loss: 0.9737\n",
      "Epoch 895/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7867 - loss: 0.4466 - val_accuracy: 0.5031 - val_loss: 0.9692\n",
      "Epoch 896/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7892 - loss: 0.4406 - val_accuracy: 0.5063 - val_loss: 0.9673\n",
      "Epoch 897/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.7914 - loss: 0.4434 - val_accuracy: 0.4975 - val_loss: 0.9758\n",
      "Epoch 898/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7822 - loss: 0.4540 - val_accuracy: 0.4975 - val_loss: 0.9765\n",
      "Epoch 899/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7883 - loss: 0.4432 - val_accuracy: 0.5106 - val_loss: 0.9772\n",
      "Epoch 900/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7898 - loss: 0.4477 - val_accuracy: 0.5069 - val_loss: 0.9803\n",
      "Epoch 901/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7939 - loss: 0.4422 - val_accuracy: 0.4969 - val_loss: 0.9866\n",
      "Epoch 902/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7892 - loss: 0.4499 - val_accuracy: 0.4994 - val_loss: 0.9877\n",
      "Epoch 903/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7875 - loss: 0.4473 - val_accuracy: 0.5013 - val_loss: 0.9816\n",
      "Epoch 904/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7914 - loss: 0.4397 - val_accuracy: 0.5000 - val_loss: 0.9836\n",
      "Epoch 905/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7788 - loss: 0.4544 - val_accuracy: 0.5044 - val_loss: 0.9805\n",
      "Epoch 906/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7922 - loss: 0.4447 - val_accuracy: 0.5056 - val_loss: 0.9853\n",
      "Epoch 907/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7916 - loss: 0.4456 - val_accuracy: 0.4950 - val_loss: 0.9836\n",
      "Epoch 908/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7955 - loss: 0.4374 - val_accuracy: 0.5038 - val_loss: 0.9758\n",
      "Epoch 909/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - accuracy: 0.7866 - loss: 0.4556 - val_accuracy: 0.4956 - val_loss: 0.9792\n",
      "Epoch 910/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7845 - loss: 0.4513 - val_accuracy: 0.4944 - val_loss: 0.9726\n",
      "Epoch 911/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7880 - loss: 0.4424 - val_accuracy: 0.5013 - val_loss: 0.9806\n",
      "Epoch 912/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7875 - loss: 0.4480 - val_accuracy: 0.5013 - val_loss: 0.9839\n",
      "Epoch 913/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7892 - loss: 0.4449 - val_accuracy: 0.4950 - val_loss: 0.9794\n",
      "Epoch 914/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7922 - loss: 0.4393 - val_accuracy: 0.4981 - val_loss: 0.9743\n",
      "Epoch 915/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7950 - loss: 0.4456 - val_accuracy: 0.5094 - val_loss: 0.9788\n",
      "Epoch 916/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7894 - loss: 0.4452 - val_accuracy: 0.4956 - val_loss: 0.9805\n",
      "Epoch 917/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7912 - loss: 0.4415 - val_accuracy: 0.5044 - val_loss: 0.9733\n",
      "Epoch 918/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7833 - loss: 0.4483 - val_accuracy: 0.4994 - val_loss: 0.9790\n",
      "Epoch 919/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7845 - loss: 0.4517 - val_accuracy: 0.5025 - val_loss: 0.9774\n",
      "Epoch 920/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7855 - loss: 0.4459 - val_accuracy: 0.5119 - val_loss: 0.9772\n",
      "Epoch 921/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7922 - loss: 0.4436 - val_accuracy: 0.5069 - val_loss: 0.9807\n",
      "Epoch 922/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7925 - loss: 0.4451 - val_accuracy: 0.5144 - val_loss: 0.9738\n",
      "Epoch 923/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7883 - loss: 0.4509 - val_accuracy: 0.5056 - val_loss: 0.9834\n",
      "Epoch 924/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7823 - loss: 0.4585 - val_accuracy: 0.5050 - val_loss: 0.9765\n",
      "Epoch 925/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7869 - loss: 0.4541 - val_accuracy: 0.5006 - val_loss: 0.9798\n",
      "Epoch 926/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7956 - loss: 0.4389 - val_accuracy: 0.4988 - val_loss: 0.9832\n",
      "Epoch 927/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8006 - loss: 0.4342 - val_accuracy: 0.4956 - val_loss: 0.9765\n",
      "Epoch 928/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7856 - loss: 0.4502 - val_accuracy: 0.5006 - val_loss: 0.9701\n",
      "Epoch 929/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7834 - loss: 0.4466 - val_accuracy: 0.5000 - val_loss: 0.9746\n",
      "Epoch 930/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.7950 - loss: 0.4386 - val_accuracy: 0.5131 - val_loss: 0.9868\n",
      "Epoch 931/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7970 - loss: 0.4381 - val_accuracy: 0.4969 - val_loss: 0.9907\n",
      "Epoch 932/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7914 - loss: 0.4409 - val_accuracy: 0.5056 - val_loss: 0.9791\n",
      "Epoch 933/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7933 - loss: 0.4484 - val_accuracy: 0.5000 - val_loss: 0.9748\n",
      "Epoch 934/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7775 - loss: 0.4576 - val_accuracy: 0.5044 - val_loss: 0.9737\n",
      "Epoch 935/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7886 - loss: 0.4509 - val_accuracy: 0.5031 - val_loss: 0.9762\n",
      "Epoch 936/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7944 - loss: 0.4371 - val_accuracy: 0.4981 - val_loss: 0.9851\n",
      "Epoch 937/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7852 - loss: 0.4464 - val_accuracy: 0.4963 - val_loss: 0.9714\n",
      "Epoch 938/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 29ms/step - accuracy: 0.7886 - loss: 0.4441 - val_accuracy: 0.4981 - val_loss: 0.9779\n",
      "Epoch 939/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - accuracy: 0.7969 - loss: 0.4360 - val_accuracy: 0.5031 - val_loss: 0.9792\n",
      "Epoch 940/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 25ms/step - accuracy: 0.7903 - loss: 0.4534 - val_accuracy: 0.5019 - val_loss: 0.9932\n",
      "Epoch 941/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7895 - loss: 0.4480 - val_accuracy: 0.4981 - val_loss: 0.9724\n",
      "Epoch 942/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7809 - loss: 0.4530 - val_accuracy: 0.5006 - val_loss: 0.9756\n",
      "Epoch 943/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7883 - loss: 0.4421 - val_accuracy: 0.5013 - val_loss: 0.9846\n",
      "Epoch 944/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7933 - loss: 0.4424 - val_accuracy: 0.5000 - val_loss: 0.9727\n",
      "Epoch 945/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7919 - loss: 0.4423 - val_accuracy: 0.5019 - val_loss: 0.9816\n",
      "Epoch 946/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7891 - loss: 0.4431 - val_accuracy: 0.5019 - val_loss: 0.9806\n",
      "Epoch 947/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7872 - loss: 0.4419 - val_accuracy: 0.5038 - val_loss: 0.9809\n",
      "Epoch 948/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7887 - loss: 0.4419 - val_accuracy: 0.5044 - val_loss: 0.9757\n",
      "Epoch 949/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7931 - loss: 0.4454 - val_accuracy: 0.4975 - val_loss: 0.9715\n",
      "Epoch 950/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step - accuracy: 0.7941 - loss: 0.4393 - val_accuracy: 0.4894 - val_loss: 0.9730\n",
      "Epoch 951/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7853 - loss: 0.4549 - val_accuracy: 0.5038 - val_loss: 0.9675\n",
      "Epoch 952/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - accuracy: 0.7891 - loss: 0.4440 - val_accuracy: 0.5075 - val_loss: 0.9784\n",
      "Epoch 953/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.7853 - loss: 0.4502 - val_accuracy: 0.5013 - val_loss: 0.9701\n",
      "Epoch 954/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7898 - loss: 0.4451 - val_accuracy: 0.5019 - val_loss: 0.9767\n",
      "Epoch 955/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7831 - loss: 0.4418 - val_accuracy: 0.5019 - val_loss: 0.9825\n",
      "Epoch 956/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7980 - loss: 0.4349 - val_accuracy: 0.5031 - val_loss: 0.9732\n",
      "Epoch 957/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7989 - loss: 0.4435 - val_accuracy: 0.5025 - val_loss: 0.9707\n",
      "Epoch 958/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7869 - loss: 0.4369 - val_accuracy: 0.5031 - val_loss: 0.9731\n",
      "Epoch 959/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.7925 - loss: 0.4400 - val_accuracy: 0.5075 - val_loss: 0.9747\n",
      "Epoch 960/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7852 - loss: 0.4505 - val_accuracy: 0.5088 - val_loss: 0.9785\n",
      "Epoch 961/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7912 - loss: 0.4432 - val_accuracy: 0.5119 - val_loss: 0.9846\n",
      "Epoch 962/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7903 - loss: 0.4423 - val_accuracy: 0.5069 - val_loss: 0.9837\n",
      "Epoch 963/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7903 - loss: 0.4454 - val_accuracy: 0.5150 - val_loss: 0.9806\n",
      "Epoch 964/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7861 - loss: 0.4521 - val_accuracy: 0.5081 - val_loss: 0.9814\n",
      "Epoch 965/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7961 - loss: 0.4343 - val_accuracy: 0.5025 - val_loss: 0.9846\n",
      "Epoch 966/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7869 - loss: 0.4417 - val_accuracy: 0.5056 - val_loss: 0.9846\n",
      "Epoch 967/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7958 - loss: 0.4429 - val_accuracy: 0.5006 - val_loss: 0.9908\n",
      "Epoch 968/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7889 - loss: 0.4435 - val_accuracy: 0.5138 - val_loss: 0.9905\n",
      "Epoch 969/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7873 - loss: 0.4418 - val_accuracy: 0.5081 - val_loss: 0.9774\n",
      "Epoch 970/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7923 - loss: 0.4415 - val_accuracy: 0.5019 - val_loss: 0.9914\n",
      "Epoch 971/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7955 - loss: 0.4405 - val_accuracy: 0.5038 - val_loss: 0.9898\n",
      "Epoch 972/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7900 - loss: 0.4471 - val_accuracy: 0.4956 - val_loss: 0.9832\n",
      "Epoch 973/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7930 - loss: 0.4344 - val_accuracy: 0.5000 - val_loss: 0.9833\n",
      "Epoch 974/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7869 - loss: 0.4503 - val_accuracy: 0.5050 - val_loss: 0.9941\n",
      "Epoch 975/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7859 - loss: 0.4473 - val_accuracy: 0.5050 - val_loss: 0.9871\n",
      "Epoch 976/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.7942 - loss: 0.4355 - val_accuracy: 0.5006 - val_loss: 0.9890\n",
      "Epoch 977/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7919 - loss: 0.4382 - val_accuracy: 0.5106 - val_loss: 0.9850\n",
      "Epoch 978/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7878 - loss: 0.4536 - val_accuracy: 0.5094 - val_loss: 0.9807\n",
      "Epoch 979/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8003 - loss: 0.4317 - val_accuracy: 0.5069 - val_loss: 0.9871\n",
      "Epoch 980/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7922 - loss: 0.4425 - val_accuracy: 0.5056 - val_loss: 0.9844\n",
      "Epoch 981/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7927 - loss: 0.4460 - val_accuracy: 0.5150 - val_loss: 0.9801\n",
      "Epoch 982/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7928 - loss: 0.4407 - val_accuracy: 0.5038 - val_loss: 0.9905\n",
      "Epoch 983/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7903 - loss: 0.4429 - val_accuracy: 0.5094 - val_loss: 0.9819\n",
      "Epoch 984/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8058 - loss: 0.4250 - val_accuracy: 0.4994 - val_loss: 0.9897\n",
      "Epoch 985/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7914 - loss: 0.4503 - val_accuracy: 0.5031 - val_loss: 0.9904\n",
      "Epoch 986/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7956 - loss: 0.4396 - val_accuracy: 0.5081 - val_loss: 0.9849\n",
      "Epoch 987/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7903 - loss: 0.4478 - val_accuracy: 0.4963 - val_loss: 0.9934\n",
      "Epoch 988/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7873 - loss: 0.4419 - val_accuracy: 0.5044 - val_loss: 0.9974\n",
      "Epoch 989/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8009 - loss: 0.4365 - val_accuracy: 0.5019 - val_loss: 1.0039\n",
      "Epoch 990/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7884 - loss: 0.4422 - val_accuracy: 0.5000 - val_loss: 0.9975\n",
      "Epoch 991/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7959 - loss: 0.4397 - val_accuracy: 0.4988 - val_loss: 0.9891\n",
      "Epoch 992/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7894 - loss: 0.4450 - val_accuracy: 0.5069 - val_loss: 0.9927\n",
      "Epoch 993/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7919 - loss: 0.4444 - val_accuracy: 0.4938 - val_loss: 0.9913\n",
      "Epoch 994/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7980 - loss: 0.4347 - val_accuracy: 0.4969 - val_loss: 1.0024\n",
      "Epoch 995/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7883 - loss: 0.4471 - val_accuracy: 0.4994 - val_loss: 0.9804\n",
      "Epoch 996/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7928 - loss: 0.4469 - val_accuracy: 0.4963 - val_loss: 0.9973\n",
      "Epoch 997/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7911 - loss: 0.4477 - val_accuracy: 0.4944 - val_loss: 0.9940\n",
      "Epoch 998/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7941 - loss: 0.4413 - val_accuracy: 0.5000 - val_loss: 1.0012\n",
      "Epoch 999/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7800 - loss: 0.4502 - val_accuracy: 0.4925 - val_loss: 1.0044\n",
      "Epoch 1000/1000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7836 - loss: 0.4571 - val_accuracy: 0.4975 - val_loss: 0.9964\n",
      "\n",
      "Model saved successfully to 'best_model.keras'\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.4840\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.49      0.48       989\n",
      "         1.0       0.49      0.48      0.48      1011\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.48      0.48      0.48      2000\n",
      "weighted avg       0.48      0.48      0.48      2000\n",
      "\n",
      "ROC AUC Score: 0.4949\n",
      "\n",
      "--- Regression Metrics on Predicted Probabilities ---\n",
      "R-squared (R2): -0.3489\n",
      "Mean Absolute Error (MAE): 0.5028\n",
      "Mean Squared Error (MSE): 0.3372\n",
      "Root Mean Squared Error (RMSE): 0.5807\n",
      "Mean Absolute Percentage Error (MAPE): 2439315494.80%\n",
      "Mean Squared Log Error (MSLE): 0.1620\n",
      "\n",
      "Model performance metrics saved to 'nn_performance_metrics.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a1844-cf79-4cb9-ac68-192bc5e2babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
