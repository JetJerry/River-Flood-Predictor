{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b93b032-aa3a-4428-94c1-cd89493c11c1",
   "metadata": {},
   "source": [
    "# the version THree of our classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e187d-63b0-41c2-b247-c692abf28b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    This version includes an improved model architecture and training\n",
    "    process with regularization and callbacks to prevent overfitting and\n",
    "    optimize performance.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Define Callbacks for Training ---\n",
    "        # EarlyStopping: Stop training when validation loss stops improving for a certain number of epochs.\n",
    "        # This prevents overfitting and saves training time.\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,  # Number of epochs with no improvement after which training will be stopped\n",
    "            restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "        )\n",
    "\n",
    "        # ReduceLROnPlateau: Reduce the learning rate when a metric has stopped improving.\n",
    "        # This can help the model find a better minimum in the loss function.\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2, # Factor by which the learning rate will be reduced\n",
    "            patience=20, # Number of epochs with no improvement after which learning rate will be reduced\n",
    "            min_lr=0.00001\n",
    "        )\n",
    "\n",
    "        # --- Improved Neural Network Model Setup ---\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with L2 regularization to prevent overfitting\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],),\n",
    "                        kernel_regularizer=l2(0.001))) # L2 regularization\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        \n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with the added callbacks\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=2000,  # Set a high number of epochs, but EarlyStopping will handle stopping\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            callbacks=[early_stopping, reduce_lr], # Pass the callbacks here\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Save the Trained Model ---\n",
    "        # Save the entire model (architecture, weights, and optimizer state)\n",
    "        model_path = 'best_model.keras'\n",
    "        model.save(model_path)\n",
    "        print(f\"\\nModel saved successfully to '{model_path}'\")\n",
    "\n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        # Mean Squared Log Error (MSLE) - check for negative values\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d524fe34-6f70-4861-b978-32f5a280fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\River-Flood-Prediction\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,433</span> (72.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m18,433\u001b[0m (72.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,433</span> (72.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,433\u001b[0m (72.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5061 - loss: 0.8675 - val_accuracy: 0.5150 - val_loss: 0.8159 - learning_rate: 0.0010\n",
      "Epoch 2/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5133 - loss: 0.7842 - val_accuracy: 0.5194 - val_loss: 0.7580 - learning_rate: 0.0010\n",
      "Epoch 3/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5169 - loss: 0.7411 - val_accuracy: 0.5044 - val_loss: 0.7292 - learning_rate: 0.0010\n",
      "Epoch 4/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5233 - loss: 0.7182 - val_accuracy: 0.5106 - val_loss: 0.7129 - learning_rate: 0.0010\n",
      "Epoch 5/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5191 - loss: 0.7071 - val_accuracy: 0.5000 - val_loss: 0.7047 - learning_rate: 0.0010\n",
      "Epoch 6/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5288 - loss: 0.7008 - val_accuracy: 0.5113 - val_loss: 0.7004 - learning_rate: 0.0010\n",
      "Epoch 7/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5298 - loss: 0.6977 - val_accuracy: 0.5144 - val_loss: 0.6978 - learning_rate: 0.0010\n",
      "Epoch 8/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5330 - loss: 0.6959 - val_accuracy: 0.5013 - val_loss: 0.6997 - learning_rate: 0.0010\n",
      "Epoch 9/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5350 - loss: 0.6948 - val_accuracy: 0.5050 - val_loss: 0.6965 - learning_rate: 0.0010\n",
      "Epoch 10/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5292 - loss: 0.6942 - val_accuracy: 0.5119 - val_loss: 0.6967 - learning_rate: 0.0010\n",
      "Epoch 11/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5278 - loss: 0.6949 - val_accuracy: 0.5000 - val_loss: 0.6975 - learning_rate: 0.0010\n",
      "Epoch 12/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5291 - loss: 0.6939 - val_accuracy: 0.5119 - val_loss: 0.6961 - learning_rate: 0.0010\n",
      "Epoch 13/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5330 - loss: 0.6937 - val_accuracy: 0.5150 - val_loss: 0.6958 - learning_rate: 0.0010\n",
      "Epoch 14/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5305 - loss: 0.6938 - val_accuracy: 0.4944 - val_loss: 0.6981 - learning_rate: 0.0010\n",
      "Epoch 15/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5353 - loss: 0.6930 - val_accuracy: 0.5175 - val_loss: 0.6963 - learning_rate: 0.0010\n",
      "Epoch 16/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 0.6931 - val_accuracy: 0.4950 - val_loss: 0.7001 - learning_rate: 0.0010\n",
      "Epoch 17/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5352 - loss: 0.6938 - val_accuracy: 0.5025 - val_loss: 0.6974 - learning_rate: 0.0010\n",
      "Epoch 18/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5378 - loss: 0.6927 - val_accuracy: 0.5119 - val_loss: 0.6963 - learning_rate: 0.0010\n",
      "Epoch 19/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5397 - loss: 0.6927 - val_accuracy: 0.5075 - val_loss: 0.6996 - learning_rate: 0.0010\n",
      "Epoch 20/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 0.6933 - val_accuracy: 0.5156 - val_loss: 0.6972 - learning_rate: 0.0010\n",
      "Epoch 21/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5375 - loss: 0.6932 - val_accuracy: 0.5100 - val_loss: 0.6963 - learning_rate: 0.0010\n",
      "Epoch 22/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5439 - loss: 0.6927 - val_accuracy: 0.5138 - val_loss: 0.6996 - learning_rate: 0.0010\n",
      "Epoch 23/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5428 - loss: 0.6928 - val_accuracy: 0.5094 - val_loss: 0.6977 - learning_rate: 0.0010\n",
      "Epoch 24/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5353 - loss: 0.6929 - val_accuracy: 0.5256 - val_loss: 0.6953 - learning_rate: 0.0010\n",
      "Epoch 25/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5373 - loss: 0.6935 - val_accuracy: 0.5100 - val_loss: 0.6966 - learning_rate: 0.0010\n",
      "Epoch 26/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5427 - loss: 0.6931 - val_accuracy: 0.5200 - val_loss: 0.6960 - learning_rate: 0.0010\n",
      "Epoch 27/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5414 - loss: 0.6923 - val_accuracy: 0.5100 - val_loss: 0.6965 - learning_rate: 0.0010\n",
      "Epoch 28/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5495 - loss: 0.6912 - val_accuracy: 0.5156 - val_loss: 0.6975 - learning_rate: 0.0010\n",
      "Epoch 29/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5462 - loss: 0.6919 - val_accuracy: 0.5119 - val_loss: 0.6968 - learning_rate: 0.0010\n",
      "Epoch 30/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5431 - loss: 0.6918 - val_accuracy: 0.5119 - val_loss: 0.6967 - learning_rate: 0.0010\n",
      "Epoch 31/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5420 - loss: 0.6925 - val_accuracy: 0.5081 - val_loss: 0.6967 - learning_rate: 0.0010\n",
      "Epoch 32/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5392 - loss: 0.6919 - val_accuracy: 0.5056 - val_loss: 0.6979 - learning_rate: 0.0010\n",
      "Epoch 33/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5469 - loss: 0.6925 - val_accuracy: 0.5081 - val_loss: 0.6979 - learning_rate: 0.0010\n",
      "Epoch 34/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5492 - loss: 0.6911 - val_accuracy: 0.5131 - val_loss: 0.6983 - learning_rate: 0.0010\n",
      "Epoch 35/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5533 - loss: 0.6909 - val_accuracy: 0.5169 - val_loss: 0.6967 - learning_rate: 0.0010\n",
      "Epoch 36/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5505 - loss: 0.6912 - val_accuracy: 0.5156 - val_loss: 0.6972 - learning_rate: 0.0010\n",
      "Epoch 37/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5527 - loss: 0.6922 - val_accuracy: 0.5081 - val_loss: 0.6986 - learning_rate: 0.0010\n",
      "Epoch 38/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5473 - loss: 0.6916 - val_accuracy: 0.5056 - val_loss: 0.6979 - learning_rate: 0.0010\n",
      "Epoch 39/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5548 - loss: 0.6909 - val_accuracy: 0.5119 - val_loss: 0.6994 - learning_rate: 0.0010\n",
      "Epoch 40/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5470 - loss: 0.6912 - val_accuracy: 0.5113 - val_loss: 0.6982 - learning_rate: 0.0010\n",
      "Epoch 41/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5569 - loss: 0.6910 - val_accuracy: 0.5144 - val_loss: 0.6981 - learning_rate: 0.0010\n",
      "Epoch 42/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5484 - loss: 0.6918 - val_accuracy: 0.5113 - val_loss: 0.6986 - learning_rate: 0.0010\n",
      "Epoch 43/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5598 - loss: 0.6901 - val_accuracy: 0.5138 - val_loss: 0.6989 - learning_rate: 0.0010\n",
      "Epoch 44/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5503 - loss: 0.6913 - val_accuracy: 0.5081 - val_loss: 0.6975 - learning_rate: 0.0010\n",
      "Epoch 45/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5597 - loss: 0.6890 - val_accuracy: 0.5175 - val_loss: 0.6971 - learning_rate: 2.0000e-04\n",
      "Epoch 46/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5616 - loss: 0.6893 - val_accuracy: 0.5181 - val_loss: 0.6980 - learning_rate: 2.0000e-04\n",
      "Epoch 47/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5648 - loss: 0.6880 - val_accuracy: 0.5113 - val_loss: 0.6986 - learning_rate: 2.0000e-04\n",
      "Epoch 48/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5580 - loss: 0.6884 - val_accuracy: 0.5200 - val_loss: 0.6987 - learning_rate: 2.0000e-04\n",
      "Epoch 49/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5663 - loss: 0.6866 - val_accuracy: 0.5119 - val_loss: 0.6987 - learning_rate: 2.0000e-04\n",
      "Epoch 50/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5598 - loss: 0.6887 - val_accuracy: 0.5119 - val_loss: 0.6999 - learning_rate: 2.0000e-04\n",
      "Epoch 51/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5673 - loss: 0.6866 - val_accuracy: 0.5163 - val_loss: 0.6994 - learning_rate: 2.0000e-04\n",
      "Epoch 52/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5678 - loss: 0.6853 - val_accuracy: 0.5194 - val_loss: 0.6996 - learning_rate: 2.0000e-04\n",
      "Epoch 53/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5716 - loss: 0.6857 - val_accuracy: 0.5150 - val_loss: 0.7000 - learning_rate: 2.0000e-04\n",
      "Epoch 54/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5642 - loss: 0.6868 - val_accuracy: 0.5144 - val_loss: 0.7003 - learning_rate: 2.0000e-04\n",
      "Epoch 55/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5703 - loss: 0.6845 - val_accuracy: 0.5131 - val_loss: 0.7005 - learning_rate: 2.0000e-04\n",
      "Epoch 56/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5600 - loss: 0.6879 - val_accuracy: 0.5125 - val_loss: 0.7004 - learning_rate: 2.0000e-04\n",
      "Epoch 57/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5647 - loss: 0.6868 - val_accuracy: 0.5156 - val_loss: 0.6998 - learning_rate: 2.0000e-04\n",
      "Epoch 58/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5645 - loss: 0.6880 - val_accuracy: 0.5125 - val_loss: 0.6992 - learning_rate: 2.0000e-04\n",
      "Epoch 59/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5742 - loss: 0.6861 - val_accuracy: 0.5150 - val_loss: 0.7000 - learning_rate: 2.0000e-04\n",
      "Epoch 60/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5683 - loss: 0.6871 - val_accuracy: 0.5106 - val_loss: 0.6994 - learning_rate: 2.0000e-04\n",
      "Epoch 61/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5667 - loss: 0.6856 - val_accuracy: 0.5144 - val_loss: 0.7007 - learning_rate: 2.0000e-04\n",
      "Epoch 62/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5672 - loss: 0.6866 - val_accuracy: 0.5181 - val_loss: 0.7003 - learning_rate: 2.0000e-04\n",
      "Epoch 63/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5645 - loss: 0.6855 - val_accuracy: 0.5188 - val_loss: 0.7008 - learning_rate: 2.0000e-04\n",
      "Epoch 64/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5727 - loss: 0.6857 - val_accuracy: 0.5150 - val_loss: 0.7005 - learning_rate: 2.0000e-04\n",
      "Epoch 65/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5652 - loss: 0.6866 - val_accuracy: 0.5144 - val_loss: 0.7006 - learning_rate: 4.0000e-05\n",
      "Epoch 66/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5709 - loss: 0.6861 - val_accuracy: 0.5163 - val_loss: 0.7004 - learning_rate: 4.0000e-05\n",
      "Epoch 67/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5667 - loss: 0.6854 - val_accuracy: 0.5181 - val_loss: 0.7005 - learning_rate: 4.0000e-05\n",
      "Epoch 68/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5648 - loss: 0.6859 - val_accuracy: 0.5175 - val_loss: 0.7005 - learning_rate: 4.0000e-05\n",
      "Epoch 69/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5766 - loss: 0.6842 - val_accuracy: 0.5188 - val_loss: 0.7007 - learning_rate: 4.0000e-05\n",
      "Epoch 70/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5692 - loss: 0.6856 - val_accuracy: 0.5181 - val_loss: 0.7006 - learning_rate: 4.0000e-05\n",
      "Epoch 71/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5670 - loss: 0.6853 - val_accuracy: 0.5163 - val_loss: 0.7006 - learning_rate: 4.0000e-05\n",
      "Epoch 72/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5769 - loss: 0.6848 - val_accuracy: 0.5163 - val_loss: 0.7007 - learning_rate: 4.0000e-05\n",
      "Epoch 73/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5694 - loss: 0.6851 - val_accuracy: 0.5138 - val_loss: 0.7008 - learning_rate: 4.0000e-05\n",
      "Epoch 74/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5750 - loss: 0.6857 - val_accuracy: 0.5138 - val_loss: 0.7008 - learning_rate: 4.0000e-05\n",
      "\n",
      "Model saved successfully to 'best_model.keras'\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.4995\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.21      0.30       989\n",
      "         1.0       0.50      0.78      0.61      1011\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.49      0.50      0.45      2000\n",
      "weighted avg       0.49      0.50      0.46      2000\n",
      "\n",
      "ROC AUC Score: 0.5054\n",
      "\n",
      "--- Regression Metrics on Predicted Probabilities ---\n",
      "R-squared (R2): -0.0053\n",
      "Mean Absolute Error (MAE): 0.4995\n",
      "Mean Squared Error (MSE): 0.2513\n",
      "Root Mean Squared Error (RMSE): 0.5013\n",
      "Mean Absolute Percentage Error (MAPE): 2607447322.05%\n",
      "Mean Squared Log Error (MSLE): 0.1258\n",
      "\n",
      "Model performance metrics saved to 'nn_performance_metrics.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a1844-cf79-4cb9-ac68-192bc5e2babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
