{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b93b032-aa3a-4428-94c1-cd89493c11c1",
   "metadata": {},
   "source": [
    "# the version Four of our classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e187d-63b0-41c2-b247-c692abf28b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    roc_auc_score, r2_score, mean_squared_error, mean_absolute_error,\n",
    "    mean_absolute_percentage_error, mean_squared_log_error\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def perform_neural_network_classification(csv_file_path):\n",
    "    \"\"\"\n",
    "    Performs neural network binary classification on a dataset, calculates\n",
    "    various classification and regression metrics, generates a confusion\n",
    "    matrix heatmap, and saves all metrics to an Excel file.\n",
    "\n",
    "    This version includes an improved model architecture and training\n",
    "    process with regularization and callbacks to prevent overfitting and\n",
    "    optimize performance.\n",
    "\n",
    "    Args:\n",
    "        csv_file_path (str): The path to the CSV file. All columns except the last\n",
    "                             are treated as features (X), and the last column,\n",
    "                             which should contain 0s and 1s, is the target variable (y).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Separate features (X) and target (y)\n",
    "        X = df.iloc[:, :-1]  # All columns except the last\n",
    "        y = df.iloc[:, -1]   # The last column (0 or 1)\n",
    "\n",
    "        # Split the data into training and testing sets (80/20 split)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        # Standardize the data to help the neural network converge faster\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "        # --- Define Callbacks for Training ---\n",
    "        # EarlyStopping: Stop training when validation loss stops improving for a certain number of epochs.\n",
    "        # This prevents overfitting and saves training time.\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=50,  # Number of epochs with no improvement after which training will be stopped\n",
    "            restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "        )\n",
    "\n",
    "        # ReduceLROnPlateau: Reduce the learning rate when a metric has stopped improving.\n",
    "        # This can help the model find a better minimum in the loss function.\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2, # Factor by which the learning rate will be reduced\n",
    "            patience=20, # Number of epochs with no improvement after which learning rate will be reduced\n",
    "            min_lr=0.00001\n",
    "        )\n",
    "\n",
    "        # --- Improved Neural Network Model Setup ---\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Input layer and first hidden layer with L2 regularization to prevent overfitting\n",
    "        model.add(Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],),\n",
    "                        kernel_regularizer=l2(0.001))) # L2 regularization\n",
    "\n",
    "        # Dropout layer to prevent overfitting\n",
    "        model.add(Dropout(0.4))\n",
    "        \n",
    "        # Second hidden layer\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "        model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "\n",
    "\n",
    "        # Output layer for binary classification with a single neuron and sigmoid activation\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        # Compile the model with the Adam optimizer and binary cross-entropy loss\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Print the model summary\n",
    "        print(\"Model Summary:\")\n",
    "        model.summary()\n",
    "        \n",
    "        # Train the model with the added callbacks\n",
    "        print(\"\\nTraining Neural Network model...\")\n",
    "        history = model.fit(\n",
    "            X_train_scaled, y_train,\n",
    "            epochs=2000,  # Set a high number of epochs, but EarlyStopping will handle stopping\n",
    "            batch_size=32,\n",
    "            validation_split=0.2,  # Use 20% of the training data for validation\n",
    "            callbacks=[early_stopping, reduce_lr], # Pass the callbacks here\n",
    "            verbose=1  # Show training progress\n",
    "        )\n",
    "        \n",
    "        # --- Save the Trained Model ---\n",
    "        # Save the entire model (architecture, weights, and optimizer state)\n",
    "        model_path = 'best_model.keras'\n",
    "        model.save(model_path)\n",
    "        print(f\"\\nModel saved successfully to '{model_path}'\")\n",
    "\n",
    "        # --- Make Predictions ---\n",
    "        # The model predicts a probability. We round it to get a binary class (0 or 1).\n",
    "        y_pred_proba = model.predict(X_test_scaled).flatten()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "        # --- 1. Calculate Classification Metrics ---\n",
    "        print(\"\\n--- Neural Network Model Performance Metrics ---\")\n",
    "\n",
    "        # Accuracy Score\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "        # Classification Report (Precision, Recall, F1-Score)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "        # ROC AUC Score\n",
    "        roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "        print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "        \n",
    "        # --- 2. Calculate Regression Metrics on Probabilities ---\n",
    "        print(\"\\n--- Regression Metrics on Predicted Probabilities ---\")\n",
    "\n",
    "        # R-squared (Coefficient of Determination)\n",
    "        r2 = r2_score(y_test, y_pred_proba)\n",
    "        print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "        # Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "\n",
    "        # Mean Squared Error (MSE)\n",
    "        mse = mean_squared_error(y_test, y_pred_proba)\n",
    "        print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "        # Root Mean Squared Error (RMSE)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "        # Mean Absolute Percentage Error (MAPE)\n",
    "        mape = np.mean(np.abs((y_test - y_pred_proba) / (y_test + 1e-8))) * 100\n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f}%\")\n",
    "\n",
    "        # Mean Squared Log Error (MSLE) - check for negative values\n",
    "        msle = mean_squared_log_error(y_test + 1e-8, y_pred_proba + 1e-8)\n",
    "        print(f\"Mean Squared Log Error (MSLE): {msle:.4f}\")\n",
    "\n",
    "        # --- 3. Save Metrics to Excel ---\n",
    "        metrics_data = {\n",
    "            'Metric': ['Accuracy', 'ROC AUC', 'R2 Score', 'MAE', 'MSE', 'RMSE', 'MAPE', 'MSLE'],\n",
    "            'Value': [accuracy, roc_auc, r2, mae, mse, rmse, mape, msle]\n",
    "        }\n",
    "        \n",
    "        metrics_df = pd.DataFrame(metrics_data)\n",
    "        excel_path = 'nn_performance_metrics.xlsx'\n",
    "        metrics_df.to_excel(excel_path, index=False)\n",
    "        print(f\"\\nModel performance metrics saved to '{excel_path}'\")\n",
    "\n",
    "        # --- 4. Generate Confusion Matrix Plot ---\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                    xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                    yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        \n",
    "        plot_path = 'confusion_matrix.svg'\n",
    "        plt.savefig(plot_path, format='svg')\n",
    "        print(f\"\\nConfusion matrix plot saved to '{plot_path}'\")\n",
    "        plt.show()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{csv_file_path}' was not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d524fe34-6f70-4861-b978-32f5a280fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\River-Flood-Prediction\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,913</span> (120.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m30,913\u001b[0m (120.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30,913</span> (120.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30,913\u001b[0m (120.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Neural Network model...\n",
      "Epoch 1/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.4922 - loss: 0.9016 - val_accuracy: 0.4762 - val_loss: 0.7630 - learning_rate: 0.0010\n",
      "Epoch 2/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4992 - loss: 0.7230 - val_accuracy: 0.5238 - val_loss: 0.7020 - learning_rate: 0.0010\n",
      "Epoch 3/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4959 - loss: 0.6971 - val_accuracy: 0.5238 - val_loss: 0.6942 - learning_rate: 0.0010\n",
      "Epoch 4/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6937 - val_accuracy: 0.5238 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 5/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4969 - loss: 0.6933 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 6/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 7/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4944 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 8/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 9/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4953 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 10/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4978 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 11/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 12/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 13/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 14/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 15/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4969 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 16/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 17/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 18/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4994 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 19/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 20/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4966 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 21/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 22/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4988 - loss: 0.6932 - val_accuracy: 0.4762 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 23/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4878 - loss: 0.6932 - val_accuracy: 0.4762 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 24/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4925 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 25/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4969 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 26/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 27/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 28/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 29/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 30/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 31/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 32/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 33/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 34/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 35/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 36/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 37/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 38/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 39/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 40/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 41/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 42/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 43/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 44/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 45/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6932 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 46/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 47/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 48/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 49/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 50/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 51/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 52/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 53/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 54/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 55/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 56/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 57/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 58/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 59/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 60/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 61/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 62/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 63/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 64/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 65/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 4.0000e-05\n",
      "Epoch 66/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 67/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 68/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 69/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 70/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 71/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 72/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 73/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 74/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 75/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "Epoch 76/2000\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5013 - loss: 0.6931 - val_accuracy: 0.5238 - val_loss: 0.6930 - learning_rate: 1.0000e-05\n",
      "\n",
      "Model saved successfully to 'best_model.keras'\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\n",
      "--- Neural Network Model Performance Metrics ---\n",
      "Accuracy: 0.5055\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00       989\n",
      "         1.0       0.51      1.00      0.67      1011\n",
      "\n",
      "    accuracy                           0.51      2000\n",
      "   macro avg       0.25      0.50      0.34      2000\n",
      "weighted avg       0.26      0.51      0.34      2000\n",
      "\n",
      "ROC AUC Score: 0.5000\n",
      "\n",
      "--- Regression Metrics on Predicted Probabilities ---\n",
      "R-squared (R2): -0.0001\n",
      "Mean Absolute Error (MAE): 0.5000\n",
      "Mean Squared Error (MSE): 0.2500\n",
      "Root Mean Squared Error (RMSE): 0.5000\n",
      "Mean Absolute Percentage Error (MAPE): 2481519221.22%\n",
      "Mean Squared Log Error (MSLE): 0.1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\River-Flood-Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\River-Flood-Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "d:\\River-Flood-Prediction\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance metrics saved to 'nn_performance_metrics.xlsx'\n",
      "\n",
      "Confusion matrix plot saved to 'confusion_matrix.svg'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perform_neural_network_classification(\"../../mapped_dataset_Normalized_version.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912a1844-cf79-4cb9-ac68-192bc5e2babd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
